{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e401c57",
   "metadata": {},
   "source": [
    "# 州累积曲线图绘制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f2dd70",
   "metadata": {},
   "source": [
    "## 0 需求文档"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd94b64",
   "metadata": {},
   "source": [
    "\n",
    "核心需求：绘制全美各个州按照优化方案部署PV的效益累积曲线，主要包含计算模块、绘图模块两个部分\n",
    "\n",
    "\n",
    "各个州的累积曲线；典型州的累积曲线（分成2部分绘制）；\n",
    "Row: 各个不同的方案、Column: 各个不同的效益维度；\n",
    "因此，一共需要出2次图，一次全美各州、一次是代表州target states。其中， target_states = ['California', 'Texas', 'Georgia', 'Indiana', 'New York']\n",
    "\n",
    "输入数据结构\n",
    "\n",
    "```python\n",
    "# 最可靠的方法：查找包含data和function目录的项目根目录\n",
    "def find_project_root(start_path=None):\n",
    "    \"\"\"查找项目根目录（包含data和function目录的目录）\"\"\"\n",
    "    if start_path is None:\n",
    "        start_path = Path.cwd()\n",
    "    \n",
    "    current = Path(start_path).resolve()\n",
    "    \n",
    "    # 向上查找，直到找到包含data和function目录的目录\n",
    "    for _ in range(5):  # 最多向上查找5层\n",
    "        if (current / 'data').exists() and (current / 'function').exists():\n",
    "            return current\n",
    "        parent = current.parent\n",
    "        if parent == current:  # 到达根目录\n",
    "            break\n",
    "        current = parent\n",
    "    \n",
    "    # 如果找不到，假设当前目录的父目录是项目根目录\n",
    "    return Path.cwd().parent\n",
    "\n",
    "project_root = find_project_root()\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "DATA_PATH = project_root / 'data'\n",
    "\n",
    "print(f\"项目根目录: {project_root}\")\n",
    "print(f\"数据路径: {DATA_PATH}\")\n",
    "df_pixel_optimized_data = pd.read_csv('data/US_data/df_pixel_optimized_data.csv')\n",
    "us_nation = gpd.read_file(r'data\\US_data\\cb_2018_us_nation_5m.shp')\n",
    "us_states = gpd.read_file(r'data\\cb_2018_us_state_500k.shp')\n",
    "\n",
    "```\n",
    "\n",
    "首先是绘图所需必要计算数据的参考\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def calculate_state_integration_analysis_simplified(pixel_optimized_data, us_states_4326, df_net_benefit, \n",
    "                                                   plot_curves=True, output_dir='data/US_data/US_analysis_reslut'):\n",
    "    \"\"\"\n",
    "    简化版：生成更简洁的州级积分统计结果\n",
    "    \"\"\"\n",
    "    print(\"=== 开始州级别累积积分统计分析（简化版）===\")\n",
    "    \n",
    "    # 1. 定义三个维度和四种排序方案\n",
    "    variables = [\n",
    "        ('predicted_prob', 'Environmental_sustainability'),\n",
    "        ('Expectation_net_benefit', 'Emission_mitigation_ability'), \n",
    "        ('avg_npv', 'Economic_feasibility')\n",
    "    ]\n",
    "    \n",
    "    solution_types = ['Environmental', 'Emission_mitigation', 'Economic', 'WCCD']\n",
    "    \n",
    "    # 2. 数据预处理\n",
    "    print(\"正在合并数据...\")\n",
    "    area_data = df_net_benefit[['lat', 'lon', 'area_m2']].copy()\n",
    "    merged_data = pixel_optimized_data.merge(area_data, on=['lat', 'lon'], how='inner')\n",
    "    area_values = merged_data['area_m2'].values / 10000\n",
    "    \n",
    "    # 3. 创建几何列，添加州标签\n",
    "    print(\"正在添加州标签...\")\n",
    "    geometry = [Point(xy) for xy in zip(merged_data['lon'], merged_data['lat'])]\n",
    "    pixel_gdf = gpd.GeoDataFrame(merged_data, geometry=geometry, crs='EPSG:4326')\n",
    "    pixel_with_states = gpd.sjoin(pixel_gdf, us_states_4326, how='left', predicate='within')\n",
    "    data_with_states = pixel_with_states.drop(columns=['geometry']).copy()\n",
    "    \n",
    "    # 4. 辅助函数\n",
    "    def percentage_to_01(percentage_array):\n",
    "        return percentage_array / 100.0\n",
    "    \n",
    "    def calculate_integral(x, y):\n",
    "        \"\"\"使用梯形法则计算积分\"\"\"\n",
    "        if len(x) < 2:\n",
    "            return 0.0\n",
    "        if x[0] > x[-1]:\n",
    "            x = x[::-1]\n",
    "            y = y[::-1]\n",
    "        integral = 0.0\n",
    "        for i in range(len(x) - 1):\n",
    "            dx = x[i+1] - x[i]\n",
    "            avg_y = (y[i] + y[i+1]) / 2.0\n",
    "            integral += avg_y * dx\n",
    "        return integral\n",
    "    \n",
    "    # 5. 获取所有州列表\n",
    "    all_states = data_with_states['NAME'].dropna().unique()\n",
    "    print(f\"发现 {len(all_states)} 个州\")\n",
    "    \n",
    "    # 6. 存储结果 - 简化结构\n",
    "    results = []\n",
    "    state_curves_data = {}\n",
    "    \n",
    "    # 7. 对每个排序方案计算总体排序和州级曲线\n",
    "    for solution_type in solution_types:\n",
    "        print(f\"正在处理排序方案: {solution_type}\")\n",
    "        \n",
    "        # 7.1 确定总体排序依据\n",
    "        if solution_type == 'WCCD':\n",
    "            sort_values = merged_data['ccd_optimized'].values\n",
    "        elif solution_type == 'Environmental':\n",
    "            sort_values = merged_data['predicted_prob'].values* area_values\n",
    "        elif solution_type == 'Emission_mitigation':\n",
    "            sort_values = merged_data['Expectation_net_benefit'].values * area_values\n",
    "        elif solution_type == 'Economic':\n",
    "            sort_values = merged_data['avg_npv'].values * area_values\n",
    "        \n",
    "        # 7.2 创建总体精细分位数区间\n",
    "        fine_percentiles = np.arange(100, -0.5, -0.5)\n",
    "        fine_bins = np.percentile(sort_values, fine_percentiles)\n",
    "        \n",
    "        # 7.3 对每个维度计算州级累积曲线\n",
    "        solution_curves = {}\n",
    "        state_integrals = {}  # 存储每个州在该排序方案下的所有维度积分\n",
    "        \n",
    "        for var_name, var_label in variables:\n",
    "            print(f\"  处理维度: {var_label}\")\n",
    "            \n",
    "            # 计算该维度的总效益值\n",
    "            if var_name == 'predicted_prob':\n",
    "                benefit_total_values = merged_data[var_name].values * area_values\n",
    "            else:\n",
    "                benefit_total_values = merged_data[var_name].values * area_values\n",
    "            \n",
    "            # 存储各州的累积曲线数据\n",
    "            state_cumulative_data = {}\n",
    "            \n",
    "            # 7.4 对每个州计算累积曲线\n",
    "            for state_name in all_states:\n",
    "                state_mask = data_with_states['NAME'] == state_name\n",
    "                state_data = data_with_states[state_mask]\n",
    "                \n",
    "                if len(state_data) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # 获取该州的数据\n",
    "                state_indices = state_data.index\n",
    "                state_benefit_values = benefit_total_values[state_indices]\n",
    "                state_sort_values = sort_values[state_indices]\n",
    "                \n",
    "                # 按照总体精细分位数区间来划分该州的数据\n",
    "                state_cumulative_benefits = []\n",
    "                \n",
    "                for i in range(len(fine_bins) - 1):\n",
    "                    mask = (state_sort_values <= fine_bins[i]) & (state_sort_values >= fine_bins[i + 1])\n",
    "                    if np.any(mask):\n",
    "                        cumulative_benefit = np.sum(state_benefit_values[mask])\n",
    "                        state_cumulative_benefits.append(cumulative_benefit)\n",
    "                    else:\n",
    "                        state_cumulative_benefits.append(0)\n",
    "                \n",
    "                # 计算累积曲线\n",
    "                state_cumulative_benefits = np.array(state_cumulative_benefits)\n",
    "                state_cumulative_sum = np.cumsum(state_cumulative_benefits)\n",
    "                state_cumulative_percentage = np.arange(len(state_cumulative_sum)) / (len(state_cumulative_sum) - 1) * 100\n",
    "                \n",
    "                # 计算积分\n",
    "                x_01 = percentage_to_01(state_cumulative_percentage)\n",
    "                integral_value = calculate_integral(x_01, state_cumulative_sum)\n",
    "                \n",
    "                # 存储积分值\n",
    "                if state_name not in state_integrals:\n",
    "                    state_integrals[state_name] = {}\n",
    "                state_integrals[state_name][var_label] = integral_value\n",
    "                \n",
    "                # 存储州级数据\n",
    "                state_cumulative_data[state_name] = {\n",
    "                    'cumulative_sum': state_cumulative_sum,\n",
    "                    'cumulative_percentage': state_cumulative_percentage,\n",
    "                    'data_count': len(state_data)\n",
    "                }\n",
    "            \n",
    "            # 存储该维度的州级曲线数据\n",
    "            solution_curves[var_label] = state_cumulative_data\n",
    "        \n",
    "        # 7.5 生成该排序方案的结果行（每个州一行）\n",
    "        for state_name in all_states:\n",
    "            if state_name in state_integrals:\n",
    "                result_row = {\n",
    "                    'State_name': state_name,\n",
    "                    'Solution_Type': solution_type,\n",
    "                    'Environmental_sustainability': state_integrals[state_name].get('Environmental_sustainability', 0),\n",
    "                    'Emission_mitigation_ability': state_integrals[state_name].get('Emission_mitigation_ability', 0),\n",
    "                    'Economic_feasibility': state_integrals[state_name].get('Economic_feasibility', 0)\n",
    "                }\n",
    "                results.append(result_row)\n",
    "        \n",
    "        # 存储该排序方案的曲线数据\n",
    "        state_curves_data[solution_type] = solution_curves\n",
    "    \n",
    "    # 8. 创建结果DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # 9. 数据清理和格式化\n",
    "    print(\"正在格式化结果...\")\n",
    "    results_df = results_df.sort_values(['State_name', 'Solution_Type']).reset_index(drop=True)\n",
    "    \n",
    "    # 数值格式化\n",
    "    numeric_columns = ['Environmental_sustainability', 'Emission_mitigation_ability', 'Economic_feasibility']\n",
    "    for col in numeric_columns:\n",
    "        results_df[col] = results_df[col].round(6)\n",
    "    \n",
    "    # 10. 绘制各州累积曲线（如果启用）\n",
    "    if plot_curves:\n",
    "        print(\"正在绘制各州累积曲线...\")\n",
    "        create_state_cumulative_curves_simplified(state_curves_data, variables, solution_types, output_dir)\n",
    "    \n",
    "    # 11. 输出摘要\n",
    "    print(f\"\\n=== 州级别累积积分统计完成 ===\")\n",
    "    print(f\"总州数: {len(all_states)}\")\n",
    "    print(f\"总记录数: {len(results_df)}\")\n",
    "    print(f\"每个州有 {len(solution_types)} 种排序方案\")\n",
    "    \n",
    "    # 显示前10个州的WCCD方案结果\n",
    "    wccd_results = results_df[results_df['Solution_Type'] == 'WCCD'].head(10)\n",
    "    print(f\"\\n前10个州的WCCD方案结果:\")\n",
    "    print(wccd_results[['State_name', 'Environmental_sustainability', \n",
    "                       'Emission_mitigation_ability', 'Economic_feasibility']].to_string(index=False))\n",
    "    \n",
    "    return results_df, state_curves_data\n",
    "\n",
    "```\n",
    "——————————————————————————————————————————————————————————————————————————————————————————————\n",
    "\n",
    "其次是绘图函数以及绘图样式的参考。绘图函数需要你重新优化组织逻辑，要求：\n",
    "（1）绘制逻辑上参考create_state_cumulative_curves_simplified，但要以 solution 为循环， 创建子图\n",
    "    for i in solution_types：\n",
    "        在改循环中创建子图（理论上每次输出subplot）的个数应该和len variables相同\n",
    "        for var_idx, (var_name, var_label) in enumerate variable:\n",
    "            获取该维度下的州级数据\n",
    "            state_data = state_curves_data[solution_type][var_label]\n",
    "                for 绘制各个州的累积曲线\n",
    "\n",
    "（2）在样式选择上，参照样式示例plot_training_loss，大概的要求是：\n",
    "    for each subplot in each solution types:\n",
    "         if target states 的绘制场景，分配 5个差异比较大的颜色\n",
    "         总体的figsize 不超过 180mm,60mm， 每个subplot 最多60 mm 的width,60 mm的heights \n",
    "         加上arrow pathch \n",
    "    \n",
    "\n",
    "```python\n",
    "def create_state_cumulative_curves_simplified(state_curves_data, variables, solution_types, output_dir):\n",
    "    \"\"\"\n",
    "    简化版：绘制各州累积曲线\n",
    "    \"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 定义颜色方案\n",
    "    solution_colors = {\n",
    "        'WCCD': '#1f77b4',      # 深蓝色\n",
    "        'Environmental': '#2ca02c',  # 深绿色\n",
    "        'Emission_mitigation': '#d62728',  # 深红色\n",
    "        'Economic': '#ff7f0e'   # 橙色\n",
    "    }\n",
    "    \n",
    "    # 为每个维度创建子图\n",
    "    for var_idx, (var_name, var_label) in enumerate(variables):\n",
    "        fig, axes = plt.subplots(1, len(solution_types), figsize=(20, 6))\n",
    "        if len(solution_types) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for sol_idx, solution_type in enumerate(solution_types):\n",
    "            ax = axes[sol_idx]\n",
    "            \n",
    "            # 获取该排序方案下该维度的州级数据\n",
    "            if solution_type in state_curves_data and var_label in state_curves_data[solution_type]:\n",
    "                state_data = state_curves_data[solution_type][var_label]\n",
    "                \n",
    "                # 绘制各州累积曲线\n",
    "                for state_name, data in state_data.items():\n",
    "                    cumulative_sum = data['cumulative_sum']\n",
    "                    cumulative_percentage = data['cumulative_percentage']\n",
    "                    \n",
    "                    # 全量绘制\n",
    "                    ax.plot(cumulative_percentage, cumulative_sum,\n",
    "                           color=solution_colors[solution_type], \n",
    "                           linewidth=1.0, alpha=0.6)\n",
    "            \n",
    "            # 设置图形属性\n",
    "            ax.set_xlim(0, 100)\n",
    "            ax.set_xlabel('Cumulative Percentage (%)', fontsize=10)\n",
    "            ax.set_ylabel(f'{var_label} (Cumulative)', fontsize=10)\n",
    "            ax.set_title(f'{solution_type}: {var_label}', fontsize=12, fontweight='bold')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 保存图片\n",
    "        output_path = f'{output_dir}/state_cumulative_curves_{var_name}_simplified.png'\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"已保存: {output_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "```\n",
    "\n",
    "```python\n",
    "def plot_training_loss(main_model_file, save_dir='Supplymentary_figure'):\n",
    "    \"\"\"\n",
    "    绘制训练损失曲线\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    main_model_file : str\n",
    "        主模型文件路径\n",
    "    save_dir : str\n",
    "        保存目录\n",
    "    \"\"\"\n",
    "    data = load_model_data(main_model_file)\n",
    "    config = data['config']\n",
    "    history = config['training_history']\n",
    "    train_loss = np.array(history['loss'])\n",
    "    val_loss = np.array(history['val_loss'])\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    # 创建图形\n",
    "    fig, ax = plt.subplots(figsize=(figsize_inches, figsize_inches))\n",
    "\n",
    "    # 绘制训练和验证损失曲线\n",
    "    ax.plot(epochs, train_loss, color='#1F78B4',\n",
    "            linewidth=1.5, label='Training Loss')\n",
    "    ax.plot(epochs, val_loss, color='#E31A1C',\n",
    "            linewidth=1.5, label='Validation Loss')\n",
    "    ax.set_xlabel('Epochs', fontweight='bold')\n",
    "    ax.set_ylabel('Loss', fontweight='bold')\n",
    "    ax.set_title('Training Loss', fontweight='bold')\n",
    "    ax.legend(frameon=False, loc='best')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    arrow_x = FancyArrowPatch(\n",
    "        posA=(ax.get_xlim()[1] * 1.0, 0),\n",
    "        posB=(ax.get_xlim()[1] * 1.03, 0),\n",
    "        transform=ax.get_xaxis_transform(),\n",
    "        arrowstyle='simple',\n",
    "        color='black', linewidth=0, mutation_scale=8, zorder=20\n",
    "    )\n",
    "    arrow_x.set_clip_on(False)\n",
    "    ax.add_patch(arrow_x)\n",
    "\n",
    "    y_lim = ax.get_ylim()\n",
    "    arrow_y = FancyArrowPatch(\n",
    "        posA=(0, y_lim[1] * 1.0),\n",
    "        posB=(0, y_lim[1] * 1.03),\n",
    "        transform=ax.get_yaxis_transform(),\n",
    "        arrowstyle='simple',\n",
    "        color='black', linewidth=0, mutation_scale=8, zorder=20\n",
    "    )\n",
    "    arrow_y.set_clip_on(False)\n",
    "    ax.add_patch(arrow_y)\n",
    "    ax.tick_params(axis='x', which='major', length=2.5, width=0.5, pad=2, labelsize=5)\n",
    "    ax.tick_params(axis='y', which='major', length=2.5, width=0.5, pad=2, labelsize=5)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, 'Figure_training_loss.png')\n",
    "    fig.savefig(save_path, dpi=300, format='png')\n",
    "    plt.close()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80675f4c",
   "metadata": {},
   "source": [
    "## 1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "240f1785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "项目根目录: C:\\Dev\\Landuse_Zhong_clean\n",
      "数据路径: C:\\Dev\\Landuse_Zhong_clean\\data\n",
      "merged_data_for_analysis shape: (70337, 13)\n",
      "merged_data_for_analysis columns: ['lat', 'lon', 'predicted_prob', 'gmm_density', 'sample_type', 'LNCS_expect', 'net_npv_usd', 'area_m2', 'E_yr_pixel', 'pv_potential_dens', 'power_generation_kwha', 'Expectation_net_benefit', 'ccd_optimized']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>predicted_prob</th>\n",
       "      <th>gmm_density</th>\n",
       "      <th>sample_type</th>\n",
       "      <th>LNCS_expect</th>\n",
       "      <th>net_npv_usd</th>\n",
       "      <th>area_m2</th>\n",
       "      <th>E_yr_pixel</th>\n",
       "      <th>pv_potential_dens</th>\n",
       "      <th>power_generation_kwha</th>\n",
       "      <th>Expectation_net_benefit</th>\n",
       "      <th>ccd_optimized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.295834</td>\n",
       "      <td>-80.287500</td>\n",
       "      <td>0.902568</td>\n",
       "      <td>2.806133e+19</td>\n",
       "      <td>prediction</td>\n",
       "      <td>811.854595</td>\n",
       "      <td>411724.028993</td>\n",
       "      <td>776295.361002</td>\n",
       "      <td>1.958127e+08</td>\n",
       "      <td>5568.344207</td>\n",
       "      <td>7.567199e+07</td>\n",
       "      <td>4756.489612</td>\n",
       "      <td>0.940305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.437500</td>\n",
       "      <td>-80.537500</td>\n",
       "      <td>0.997976</td>\n",
       "      <td>5.399806e+21</td>\n",
       "      <td>prediction</td>\n",
       "      <td>1348.189022</td>\n",
       "      <td>287052.220262</td>\n",
       "      <td>775385.854124</td>\n",
       "      <td>1.913273e+08</td>\n",
       "      <td>5447.174926</td>\n",
       "      <td>7.402534e+07</td>\n",
       "      <td>4098.985904</td>\n",
       "      <td>0.828012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.437500</td>\n",
       "      <td>-80.495834</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>1.508036e+20</td>\n",
       "      <td>prediction</td>\n",
       "      <td>971.186274</td>\n",
       "      <td>278019.855286</td>\n",
       "      <td>775385.854124</td>\n",
       "      <td>1.910215e+08</td>\n",
       "      <td>5438.469092</td>\n",
       "      <td>7.390703e+07</td>\n",
       "      <td>4467.282818</td>\n",
       "      <td>0.882208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.445833</td>\n",
       "      <td>-80.454170</td>\n",
       "      <td>0.990886</td>\n",
       "      <td>1.800785e+16</td>\n",
       "      <td>prediction</td>\n",
       "      <td>972.811005</td>\n",
       "      <td>272893.696918</td>\n",
       "      <td>775332.207938</td>\n",
       "      <td>1.908320e+08</td>\n",
       "      <td>5433.449375</td>\n",
       "      <td>7.383881e+07</td>\n",
       "      <td>4460.638370</td>\n",
       "      <td>0.880366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.445833</td>\n",
       "      <td>-80.404170</td>\n",
       "      <td>0.996591</td>\n",
       "      <td>6.792866e+22</td>\n",
       "      <td>prediction</td>\n",
       "      <td>968.544647</td>\n",
       "      <td>294800.434504</td>\n",
       "      <td>775332.207938</td>\n",
       "      <td>1.915894e+08</td>\n",
       "      <td>5455.012162</td>\n",
       "      <td>7.413184e+07</td>\n",
       "      <td>4486.467516</td>\n",
       "      <td>0.888518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat        lon  predicted_prob   gmm_density sample_type  \\\n",
       "0  25.295834 -80.287500        0.902568  2.806133e+19  prediction   \n",
       "1  25.437500 -80.537500        0.997976  5.399806e+21  prediction   \n",
       "2  25.437500 -80.495834        0.995833  1.508036e+20  prediction   \n",
       "3  25.445833 -80.454170        0.990886  1.800785e+16  prediction   \n",
       "4  25.445833 -80.404170        0.996591  6.792866e+22  prediction   \n",
       "\n",
       "   LNCS_expect    net_npv_usd        area_m2    E_yr_pixel  pv_potential_dens  \\\n",
       "0   811.854595  411724.028993  776295.361002  1.958127e+08        5568.344207   \n",
       "1  1348.189022  287052.220262  775385.854124  1.913273e+08        5447.174926   \n",
       "2   971.186274  278019.855286  775385.854124  1.910215e+08        5438.469092   \n",
       "3   972.811005  272893.696918  775332.207938  1.908320e+08        5433.449375   \n",
       "4   968.544647  294800.434504  775332.207938  1.915894e+08        5455.012162   \n",
       "\n",
       "   power_generation_kwha  Expectation_net_benefit  ccd_optimized  \n",
       "0           7.567199e+07              4756.489612       0.940305  \n",
       "1           7.402534e+07              4098.985904       0.828012  \n",
       "2           7.390703e+07              4467.282818       0.882208  \n",
       "3           7.383881e+07              4460.638370       0.880366  \n",
       "4           7.413184e+07              4486.467516       0.888518  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "def find_project_root(start_path=None):\n",
    "    \"\"\"查找项目根目录（包含data和function目录的目录）\"\"\"\n",
    "    if start_path is None:\n",
    "        start_path = Path.cwd()\n",
    "    \n",
    "    current = Path(start_path).resolve()\n",
    "    \n",
    "    # 向上查找，直到找到包含data和function目录的目录\n",
    "    for _ in range(5):  # 最多向上查找5层\n",
    "        if (current / 'data').exists() and (current / 'function').exists():\n",
    "            return current\n",
    "        parent = current.parent\n",
    "        if parent == current:  # 到达根目录\n",
    "            break\n",
    "        current = parent\n",
    "    \n",
    "    # 如果找不到，假设当前目录的父目录是项目根目录\n",
    "    return Path.cwd().parent\n",
    "\n",
    "project_root = find_project_root()\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "DATA_PATH = project_root / 'data'\n",
    "\n",
    "print(f\"项目根目录: {project_root}\")\n",
    "print(f\"数据路径: {DATA_PATH}\")\n",
    "\n",
    "# 加载合并后的分析数据\n",
    "merged_data_for_analysis = pd.read_csv(DATA_PATH / 'US_data/df_merged_data_for_analysis.csv')\n",
    "us_states = gpd.read_file(DATA_PATH / 'cb_2018_us_state_500k.shp')\n",
    "us_states_4326 = us_states.to_crs('EPSG:4326')\n",
    "\n",
    "print(f\"merged_data_for_analysis shape: {merged_data_for_analysis.shape}\")\n",
    "print(f\"merged_data_for_analysis columns: {merged_data_for_analysis.columns.tolist()}\")\n",
    "merged_data_for_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eef688c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>predicted_prob</th>\n",
       "      <th>gmm_density</th>\n",
       "      <th>sample_type</th>\n",
       "      <th>LNCS_expect</th>\n",
       "      <th>net_npv_usd</th>\n",
       "      <th>area_m2</th>\n",
       "      <th>E_yr_pixel</th>\n",
       "      <th>pv_potential_dens</th>\n",
       "      <th>power_generation_kwha</th>\n",
       "      <th>Expectation_net_benefit</th>\n",
       "      <th>ccd_optimized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.295834</td>\n",
       "      <td>-80.287500</td>\n",
       "      <td>0.902568</td>\n",
       "      <td>2.806133e+19</td>\n",
       "      <td>prediction</td>\n",
       "      <td>811.854595</td>\n",
       "      <td>411724.028993</td>\n",
       "      <td>776295.361002</td>\n",
       "      <td>1.958127e+08</td>\n",
       "      <td>5568.344207</td>\n",
       "      <td>7.567199e+07</td>\n",
       "      <td>4756.489612</td>\n",
       "      <td>0.940305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.437500</td>\n",
       "      <td>-80.537500</td>\n",
       "      <td>0.997976</td>\n",
       "      <td>5.399806e+21</td>\n",
       "      <td>prediction</td>\n",
       "      <td>1348.189022</td>\n",
       "      <td>287052.220262</td>\n",
       "      <td>775385.854124</td>\n",
       "      <td>1.913273e+08</td>\n",
       "      <td>5447.174926</td>\n",
       "      <td>7.402534e+07</td>\n",
       "      <td>4098.985904</td>\n",
       "      <td>0.828012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.437500</td>\n",
       "      <td>-80.495834</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>1.508036e+20</td>\n",
       "      <td>prediction</td>\n",
       "      <td>971.186274</td>\n",
       "      <td>278019.855286</td>\n",
       "      <td>775385.854124</td>\n",
       "      <td>1.910215e+08</td>\n",
       "      <td>5438.469092</td>\n",
       "      <td>7.390703e+07</td>\n",
       "      <td>4467.282818</td>\n",
       "      <td>0.882208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.445833</td>\n",
       "      <td>-80.454170</td>\n",
       "      <td>0.990886</td>\n",
       "      <td>1.800785e+16</td>\n",
       "      <td>prediction</td>\n",
       "      <td>972.811005</td>\n",
       "      <td>272893.696918</td>\n",
       "      <td>775332.207938</td>\n",
       "      <td>1.908320e+08</td>\n",
       "      <td>5433.449375</td>\n",
       "      <td>7.383881e+07</td>\n",
       "      <td>4460.638370</td>\n",
       "      <td>0.880366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.445833</td>\n",
       "      <td>-80.404170</td>\n",
       "      <td>0.996591</td>\n",
       "      <td>6.792866e+22</td>\n",
       "      <td>prediction</td>\n",
       "      <td>968.544647</td>\n",
       "      <td>294800.434504</td>\n",
       "      <td>775332.207938</td>\n",
       "      <td>1.915894e+08</td>\n",
       "      <td>5455.012162</td>\n",
       "      <td>7.413184e+07</td>\n",
       "      <td>4486.467516</td>\n",
       "      <td>0.888518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70332</th>\n",
       "      <td>48.995834</td>\n",
       "      <td>-99.995834</td>\n",
       "      <td>0.914557</td>\n",
       "      <td>5.692829e+14</td>\n",
       "      <td>prediction</td>\n",
       "      <td>377.830800</td>\n",
       "      <td>-556486.868714</td>\n",
       "      <td>563356.382622</td>\n",
       "      <td>1.180457e+08</td>\n",
       "      <td>4625.717362</td>\n",
       "      <td>6.286200e+07</td>\n",
       "      <td>4247.886562</td>\n",
       "      <td>0.790359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70333</th>\n",
       "      <td>48.995834</td>\n",
       "      <td>-99.987500</td>\n",
       "      <td>0.921603</td>\n",
       "      <td>1.413612e+14</td>\n",
       "      <td>prediction</td>\n",
       "      <td>307.516600</td>\n",
       "      <td>-562376.609379</td>\n",
       "      <td>563356.382622</td>\n",
       "      <td>1.178997e+08</td>\n",
       "      <td>4619.997412</td>\n",
       "      <td>6.278426e+07</td>\n",
       "      <td>4312.480812</td>\n",
       "      <td>0.800732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70334</th>\n",
       "      <td>48.995834</td>\n",
       "      <td>-99.895836</td>\n",
       "      <td>0.872176</td>\n",
       "      <td>3.161397e+13</td>\n",
       "      <td>prediction</td>\n",
       "      <td>324.674320</td>\n",
       "      <td>-598319.346882</td>\n",
       "      <td>563356.382622</td>\n",
       "      <td>1.170071e+08</td>\n",
       "      <td>4585.017928</td>\n",
       "      <td>6.230891e+07</td>\n",
       "      <td>4260.343608</td>\n",
       "      <td>0.757385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70335</th>\n",
       "      <td>48.995834</td>\n",
       "      <td>-99.887500</td>\n",
       "      <td>0.799749</td>\n",
       "      <td>6.767585e+13</td>\n",
       "      <td>prediction</td>\n",
       "      <td>323.374660</td>\n",
       "      <td>-594934.043507</td>\n",
       "      <td>563356.382622</td>\n",
       "      <td>1.170906e+08</td>\n",
       "      <td>4588.290785</td>\n",
       "      <td>6.235338e+07</td>\n",
       "      <td>4264.916125</td>\n",
       "      <td>0.691242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70336</th>\n",
       "      <td>48.995834</td>\n",
       "      <td>-97.237500</td>\n",
       "      <td>0.916865</td>\n",
       "      <td>1.485307e+24</td>\n",
       "      <td>prediction</td>\n",
       "      <td>350.892774</td>\n",
       "      <td>-609181.061657</td>\n",
       "      <td>563356.382622</td>\n",
       "      <td>1.167584e+08</td>\n",
       "      <td>4575.274956</td>\n",
       "      <td>6.217650e+07</td>\n",
       "      <td>4224.382182</td>\n",
       "      <td>0.784443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70337 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lat        lon  predicted_prob   gmm_density sample_type  \\\n",
       "0      25.295834 -80.287500        0.902568  2.806133e+19  prediction   \n",
       "1      25.437500 -80.537500        0.997976  5.399806e+21  prediction   \n",
       "2      25.437500 -80.495834        0.995833  1.508036e+20  prediction   \n",
       "3      25.445833 -80.454170        0.990886  1.800785e+16  prediction   \n",
       "4      25.445833 -80.404170        0.996591  6.792866e+22  prediction   \n",
       "...          ...        ...             ...           ...         ...   \n",
       "70332  48.995834 -99.995834        0.914557  5.692829e+14  prediction   \n",
       "70333  48.995834 -99.987500        0.921603  1.413612e+14  prediction   \n",
       "70334  48.995834 -99.895836        0.872176  3.161397e+13  prediction   \n",
       "70335  48.995834 -99.887500        0.799749  6.767585e+13  prediction   \n",
       "70336  48.995834 -97.237500        0.916865  1.485307e+24  prediction   \n",
       "\n",
       "       LNCS_expect    net_npv_usd        area_m2    E_yr_pixel  \\\n",
       "0       811.854595  411724.028993  776295.361002  1.958127e+08   \n",
       "1      1348.189022  287052.220262  775385.854124  1.913273e+08   \n",
       "2       971.186274  278019.855286  775385.854124  1.910215e+08   \n",
       "3       972.811005  272893.696918  775332.207938  1.908320e+08   \n",
       "4       968.544647  294800.434504  775332.207938  1.915894e+08   \n",
       "...            ...            ...            ...           ...   \n",
       "70332   377.830800 -556486.868714  563356.382622  1.180457e+08   \n",
       "70333   307.516600 -562376.609379  563356.382622  1.178997e+08   \n",
       "70334   324.674320 -598319.346882  563356.382622  1.170071e+08   \n",
       "70335   323.374660 -594934.043507  563356.382622  1.170906e+08   \n",
       "70336   350.892774 -609181.061657  563356.382622  1.167584e+08   \n",
       "\n",
       "       pv_potential_dens  power_generation_kwha  Expectation_net_benefit  \\\n",
       "0            5568.344207           7.567199e+07              4756.489612   \n",
       "1            5447.174926           7.402534e+07              4098.985904   \n",
       "2            5438.469092           7.390703e+07              4467.282818   \n",
       "3            5433.449375           7.383881e+07              4460.638370   \n",
       "4            5455.012162           7.413184e+07              4486.467516   \n",
       "...                  ...                    ...                      ...   \n",
       "70332        4625.717362           6.286200e+07              4247.886562   \n",
       "70333        4619.997412           6.278426e+07              4312.480812   \n",
       "70334        4585.017928           6.230891e+07              4260.343608   \n",
       "70335        4588.290785           6.235338e+07              4264.916125   \n",
       "70336        4575.274956           6.217650e+07              4224.382182   \n",
       "\n",
       "       ccd_optimized  \n",
       "0           0.940305  \n",
       "1           0.828012  \n",
       "2           0.882208  \n",
       "3           0.880366  \n",
       "4           0.888518  \n",
       "...              ...  \n",
       "70332       0.790359  \n",
       "70333       0.800732  \n",
       "70334       0.757385  \n",
       "70335       0.691242  \n",
       "70336       0.784443  \n",
       "\n",
       "[70337 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_for_analysis = pd.read_csv(DATA_PATH / 'US_data/df_merged_data_for_analysis.csv')\n",
    "merged_data_for_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a6306",
   "metadata": {},
   "source": [
    "## 2. Calculation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a8b8ce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_state_integration_analysis_simplified(merged_data_for_analysis, us_states_4326, \n",
    "                                                   plot_curves=False, output_dir='data/US_data/US_analysis_reslut'):\n",
    "    \"\"\"\n",
    "    简化版：生成更简洁的州级积分统计结果\n",
    "    \"\"\"\n",
    "    print(\"=== 开始州级别累积积分统计分析（简化版）===\")\n",
    "    \n",
    "    # 1. 定义三个维度和四种排序方案\n",
    "    variables = [\n",
    "        ('predicted_prob', 'Environmental_sustainability'),\n",
    "        ('Expectation_net_benefit', 'Emission_mitigation_ability'), \n",
    "        ('net_npv_usd', 'Economic_feasibility')\n",
    "    ]\n",
    "    \n",
    "    solution_types = ['Environmental suitability', 'Emission mitigation ability', 'Economic viability', '3E-synergy']\n",
    "    \n",
    "    # 2. 数据预处理\n",
    "    print(\"正在处理数据...\")\n",
    "    # 直接使用merged_data_for_analysis，确保包含所需列\n",
    "    merged_data = merged_data_for_analysis.copy()\n",
    "    \n",
    "    # 检查必需的列是否存在\n",
    "    required_columns = ['lat', 'lon', 'area_m2', 'predicted_prob', 'Expectation_net_benefit', 'ccd_optimized']\n",
    "    missing_columns = [col for col in required_columns if col not in merged_data.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"缺少必需的列: {missing_columns}\")\n",
    "    \n",
    "    if 'net_npv_usd' not in merged_data.columns:\n",
    "        print(\"警告: merged_data_for_analysis中缺少avg_npv列，需要从df_economic合并\")\n",
    "    \n",
    "    area_values = merged_data['area_m2'].values / 10000\n",
    "    \n",
    "    # 3. 创建几何列，添加州标签\n",
    "    print(\"正在添加州标签...\")\n",
    "    geometry = [Point(xy) for xy in zip(merged_data['lon'], merged_data['lat'])]\n",
    "    pixel_gdf = gpd.GeoDataFrame(merged_data, geometry=geometry, crs='EPSG:4326')\n",
    "    pixel_with_states = gpd.sjoin(pixel_gdf, us_states_4326, how='left', predicate='within')\n",
    "    data_with_states = pixel_with_states.drop(columns=['geometry']).copy()\n",
    "    \n",
    "    # 4. 辅助函数\n",
    "    def percentage_to_01(percentage_array):\n",
    "        return percentage_array / 100.0\n",
    "    \n",
    "    def calculate_integral(x, y):\n",
    "        \"\"\"使用梯形法则计算积分\"\"\"\n",
    "        if len(x) < 2:\n",
    "            return 0.0\n",
    "        if x[0] > x[-1]:\n",
    "            x = x[::-1]\n",
    "            y = y[::-1]\n",
    "        integral = 0.0\n",
    "        for i in range(len(x) - 1):\n",
    "            dx = x[i+1] - x[i]\n",
    "            avg_y = (y[i] + y[i+1]) / 2.0\n",
    "            integral += avg_y * dx\n",
    "        return integral\n",
    "    \n",
    "    # 5. 获取所有州列表\n",
    "    all_states = data_with_states['NAME'].dropna().unique()\n",
    "    print(f\"发现 {len(all_states)} 个州\")\n",
    "    \n",
    "    # 6. 存储结果 - 简化结构\n",
    "    results = []\n",
    "    state_curves_data = {}\n",
    "    \n",
    "    # 7. 对每个排序方案计算总体排序和州级曲线\n",
    "    for solution_type in solution_types:\n",
    "        print(f\"正在处理排序方案: {solution_type}\")\n",
    "        \n",
    "        # 7.1 确定总体排序依据\n",
    "        if solution_type == '3E-synergy':\n",
    "            sort_values = merged_data['ccd_optimized'].values\n",
    "        elif solution_type == 'Environmental suitability':\n",
    "            sort_values = merged_data['predicted_prob'].values * area_values\n",
    "        elif solution_type == 'Emission mitigation ability':\n",
    "            sort_values = merged_data['Expectation_net_benefit'].values * area_values\n",
    "        elif solution_type == 'Economic viability':\n",
    "            sort_values = merged_data['net_npv_usd'].values * area_values\n",
    "        else:\n",
    "            raise ValueError(f\"未知的排序方案: {solution_type}\")\n",
    "        \n",
    "        # 7.2 创建总体精细分位数区间\n",
    "        fine_percentiles = np.arange(100, -0.5, -0.5)\n",
    "        fine_bins = np.percentile(sort_values, fine_percentiles)\n",
    "        \n",
    "        # 7.3 对每个维度计算州级累积曲线\n",
    "        solution_curves = {}\n",
    "        state_integrals = {}  # 存储每个州在该排序方案下的所有维度积分\n",
    "        \n",
    "        for var_name, var_label in variables:\n",
    "            print(f\"  处理维度: {var_label}\")\n",
    "            \n",
    "            # 计算该维度的总效益值\n",
    "            if var_name == 'predicted_prob':\n",
    "                benefit_total_values = merged_data[var_name].values * area_values\n",
    "            else:\n",
    "                benefit_total_values = merged_data[var_name].values * area_values\n",
    "            \n",
    "            # 存储各州的累积曲线数据\n",
    "            state_cumulative_data = {}\n",
    "            \n",
    "            # 7.4 对每个州计算累积曲线\n",
    "            for state_name in all_states:\n",
    "                state_mask = data_with_states['NAME'] == state_name\n",
    "                state_data = data_with_states[state_mask]\n",
    "                \n",
    "                if len(state_data) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # 获取该州的数据\n",
    "                state_indices = state_data.index\n",
    "                state_benefit_values = benefit_total_values[state_indices]\n",
    "                state_sort_values = sort_values[state_indices]\n",
    "                \n",
    "                # 按照总体精细分位数区间来划分该州的数据\n",
    "                state_cumulative_benefits = []\n",
    "                \n",
    "                for i in range(len(fine_bins) - 1):\n",
    "                    mask = (state_sort_values <= fine_bins[i]) & (state_sort_values >= fine_bins[i + 1])\n",
    "                    if np.any(mask):\n",
    "                        cumulative_benefit = np.sum(state_benefit_values[mask])\n",
    "                        state_cumulative_benefits.append(cumulative_benefit)\n",
    "                    else:\n",
    "                        state_cumulative_benefits.append(0)\n",
    "                \n",
    "                # 计算累积曲线\n",
    "                state_cumulative_benefits = np.array(state_cumulative_benefits)\n",
    "                state_cumulative_sum = np.cumsum(state_cumulative_benefits)\n",
    "                state_cumulative_percentage = np.arange(len(state_cumulative_sum)) / (len(state_cumulative_sum) - 1) * 100\n",
    "                \n",
    "                # 计算积分\n",
    "                x_01 = percentage_to_01(state_cumulative_percentage)\n",
    "                integral_value = calculate_integral(x_01, state_cumulative_sum)\n",
    "                \n",
    "                # 存储积分值\n",
    "                if state_name not in state_integrals:\n",
    "                    state_integrals[state_name] = {}\n",
    "                state_integrals[state_name][var_label] = integral_value\n",
    "                \n",
    "                # 存储州级数据\n",
    "                state_cumulative_data[state_name] = {\n",
    "                    'cumulative_sum': state_cumulative_sum,\n",
    "                    'cumulative_percentage': state_cumulative_percentage,\n",
    "                    'data_count': len(state_data)\n",
    "                }\n",
    "            \n",
    "            # 存储该维度的州级曲线数据\n",
    "            solution_curves[var_label] = state_cumulative_data\n",
    "        \n",
    "        # 7.5 生成该排序方案的结果行（每个州一行）\n",
    "        for state_name in all_states:\n",
    "            if state_name in state_integrals:\n",
    "                result_row = {\n",
    "                    'State_name': state_name,\n",
    "                    'Solution_Type': solution_type,\n",
    "                    'Environmental_sustainability': state_integrals[state_name].get('Environmental_sustainability', 0),\n",
    "                    'Emission_mitigation_ability': state_integrals[state_name].get('Emission_mitigation_ability', 0),\n",
    "                    'Economic_feasibility': state_integrals[state_name].get('Economic_feasibility', 0)\n",
    "                }\n",
    "                results.append(result_row)\n",
    "        \n",
    "        # 存储该排序方案的曲线数据\n",
    "        state_curves_data[solution_type] = solution_curves\n",
    "    \n",
    "    # 8. 创建结果DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # 9. 数据清理和格式化\n",
    "    print(\"正在格式化结果...\")\n",
    "    results_df = results_df.sort_values(['State_name', 'Solution_Type']).reset_index(drop=True)\n",
    "    \n",
    "    # 数值格式化\n",
    "    numeric_columns = ['Environmental_sustainability', 'Emission_mitigation_ability', 'Economic_feasibility']\n",
    "    for col in numeric_columns:\n",
    "        results_df[col] = results_df[col].round(6)\n",
    "    \n",
    "    # 10. 绘制各州累积曲线（如果启用）\n",
    "    if plot_curves:\n",
    "        print(\"正在绘制各州累积曲线...\")\n",
    "        # Note: This would call the old simplified plotting function if needed\n",
    "        pass\n",
    "    \n",
    "    # 11. 输出摘要\n",
    "    print(f\"\\n=== 州级别累积积分统计完成 ===\")\n",
    "    print(f\"总州数: {len(all_states)}\")\n",
    "    print(f\"总记录数: {len(results_df)}\")\n",
    "    print(f\"每个州有 {len(solution_types)} 种排序方案\")\n",
    "    \n",
    "    # 显示前10个州的WCCD方案结果\n",
    "    wccd_results = results_df[results_df['Solution_Type'] == '3E-synergy'].head(10)\n",
    "    print(f\"\\n前10个州的WCCD方案结果:\")\n",
    "    print(wccd_results[['State_name', 'Environmental_sustainability', \n",
    "                       'Emission_mitigation_ability', 'Economic_feasibility']].to_string(index=False))\n",
    "    \n",
    "    return results_df, state_curves_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3f7e0541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib默认参数设置完成\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置matplotlib默认参数（参考S2_LNCS_carbon.ipynb）\n",
    "plt.rcParams.update({\n",
    "    'font.size': 5, \n",
    "    'axes.titlesize': 5, \n",
    "    'axes.labelsize': 5,\n",
    "    'xtick.labelsize': 5, \n",
    "    'ytick.labelsize': 5, \n",
    "    'legend.fontsize': 5,\n",
    "    'font.family': 'Arial'\n",
    "})\n",
    "\n",
    "print(\"Matplotlib默认参数设置完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3956c97d",
   "metadata": {},
   "source": [
    "## 3. Publication-quality plotting function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1633d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state_cumulative_curves_publication(state_curves_data, variables, solution_types, \n",
    "                                                target_states=None, output_dir='Supplymentary/Supplymentary_figure'):\n",
    "    \"\"\"\n",
    "    绘制出版质量的州级累积曲线图\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    state_curves_data : dict\n",
    "        州级累积曲线数据字典\n",
    "    variables : list\n",
    "        变量列表，格式为 [('var_name', 'var_label'), ...]\n",
    "    solution_types : list\n",
    "        排序方案列表\n",
    "    target_states : list, optional\n",
    "        目标州列表，如果提供则只绘制这些州的曲线（使用不同颜色）\n",
    "    output_dir : str\n",
    "        输出目录\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.patches import FancyArrowPatch\n",
    "    from matplotlib.ticker import FuncFormatter\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    # 为每个维度选择主色调（使用较深的颜色）\n",
    "    # 注意：键名使用下划线格式，与var_label匹配\n",
    "    dimension_colors = {\n",
    "        'Environmental_sustainability': '#7b1fa2',  \n",
    "        'Emission_mitigation_ability': '#005824',   \n",
    "        'Economic_feasibility': '#a36d1c'          \n",
    "    }\n",
    "    \n",
    "    # 方案颜色（用于3E-synergy，其他方案使用维度颜色）\n",
    "    solution_colors = {\n",
    "        '3E-synergy': '#1f77b4',           \n",
    "        'Environmental suitability': dimension_colors['Environmental_sustainability'],  # 紫色\n",
    "        'Emission mitigation ability': dimension_colors['Emission_mitigation_ability'],  # 绿色\n",
    "        'Economic viability': dimension_colors['Economic_feasibility']  # 黄色/棕色\n",
    "    }\n",
    "    \n",
    "    # 目标州的5种不同颜色（使用维度颜色系中的不同深浅）\n",
    "    target_state_colors = [\n",
    "        '#1f77b4',  \n",
    "        '#d62728',  \n",
    "        '#2ca02c',  \n",
    "        '#ff7f0e',  \n",
    "        '#9467bd'   \n",
    "    ]\n",
    "    \n",
    "    # 方案对应的线型（参考6.9 Figure4_Cumulative_pirority.ipynb）\n",
    "    solution_linestyles = {\n",
    "        'Environmental suitability': ':',        # 点线 (对应predicted_prob)\n",
    "        'Emission mitigation ability': '--',  # 虚线 (对应Expectation_net_benefit)\n",
    "        'Economic viability': '-',               # 实线 (对应avg_npv)\n",
    "        '3E-synergy': '-.'                   # 点划线 (对应ccd_optimized)\n",
    "    }\n",
    "    \n",
    "    # 尺寸设置（mm转inches）\n",
    "    fig_width_mm = 175\n",
    "    fig_height_mm = 50\n",
    "    subplot_width_mm = 60\n",
    "    subplot_height_mm = 40\n",
    "    \n",
    "    fig_width_inches = fig_width_mm / 25.4\n",
    "    fig_height_inches = fig_height_mm / 25.4\n",
    "    subplot_width_inches = subplot_width_mm / 25.4\n",
    "    subplot_height_inches = subplot_height_mm / 25.4\n",
    "    \n",
    "    # 对每个排序方案创建图形\n",
    "    for sol_idx, solution_type in enumerate(solution_types):\n",
    "        print(f\"正在绘制排序方案: {solution_type}\")\n",
    "        \n",
    "        # 创建图形，1行3列（3个变量）\n",
    "        fig, axes = plt.subplots(1, len(variables), \n",
    "                                 figsize=(fig_width_inches, fig_height_inches))\n",
    "        \n",
    "        if len(variables) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        # 用于存储图例信息（仅在target_states场景下使用）\n",
    "        legend_handles = []\n",
    "        legend_labels = []\n",
    "        \n",
    "        # 对每个变量（维度）创建子图\n",
    "        for var_idx, (var_name, var_label) in enumerate(variables):\n",
    "            ax = axes[var_idx]\n",
    "            \n",
    "            # 获取该排序方案下该维度的州级数据\n",
    "            if solution_type in state_curves_data and var_label in state_curves_data[solution_type]:\n",
    "                state_data = state_curves_data[solution_type][var_label]\n",
    "\n",
    "\n",
    "                # 计算所有曲线的最大值和最小值（用于设置y轴范围）\n",
    "                all_cumulative_sums = []\n",
    "                for data in state_data.values():\n",
    "                    all_cumulative_sums.extend(data['cumulative_sum'])\n",
    "                \n",
    "                if len(all_cumulative_sums) > 0:\n",
    "                    all_cumulative_sums = np.array(all_cumulative_sums)\n",
    "                    all_curves_max = np.max(all_cumulative_sums)\n",
    "                    all_curves_min = np.min(all_cumulative_sums)\n",
    "                else:\n",
    "                    all_curves_max = 0\n",
    "                    all_curves_min = 0\n",
    "                \n",
    "                # 判断是绘制所有州还是只绘制目标州\n",
    "                if target_states is not None:\n",
    "                    # 目标州场景：5个目标州用不同颜色，其他州用灰色\n",
    "                    state_color_map = {}\n",
    "                    for idx, state in enumerate(target_states):\n",
    "                        if state in state_data:\n",
    "                            state_color_map[state] = target_state_colors[idx % len(target_state_colors)]\n",
    "                    \n",
    "                    # 先绘制其他州（灰色背景）\n",
    "                    for state_name, data in state_data.items():\n",
    "                        if state_name not in state_color_map:\n",
    "                            cumulative_sum = data['cumulative_sum']\n",
    "                            cumulative_percentage = data['cumulative_percentage']\n",
    "                            ax.plot(cumulative_percentage, cumulative_sum,\n",
    "                                   color='#cccccc', linewidth=0.5, alpha=0.3)\n",
    "                    \n",
    "                    # 获取当前方案对应的线型\n",
    "                    linestyle = solution_linestyles.get(solution_type, '-')\n",
    "\n",
    "                    for state_name in target_states:\n",
    "                        if state_name in state_data:\n",
    "                            data = state_data[state_name]\n",
    "                            cumulative_sum = data['cumulative_sum']\n",
    "                            cumulative_percentage = data['cumulative_percentage']\n",
    "                            \n",
    "                            if var_idx == 0:\n",
    "                                legend_label = f\"{state_name}\"\n",
    "                                line, = ax.plot(cumulative_percentage, cumulative_sum,\n",
    "                                               color=state_color_map[state_name],\n",
    "                                               linestyle=linestyle,\n",
    "                                               linewidth=1.5, alpha=0.8, label=legend_label)\n",
    "                                if state_name not in legend_labels:\n",
    "                                    legend_handles.append(line)\n",
    "                                    legend_labels.append(legend_label)\n",
    "                            else:\n",
    "                                ax.plot(cumulative_percentage, cumulative_sum,\n",
    "                                       color=state_color_map[state_name],\n",
    "                                       linestyle=linestyle,\n",
    "                                       linewidth=1.5, alpha=0.8)\n",
    "                else:\n",
    "                    dimension_color = dimension_colors.get(var_label, solution_colors.get(solution_type, '#1f77b4'))\n",
    "                    for state_name, data in state_data.items():\n",
    "                        cumulative_sum = data['cumulative_sum']\n",
    "                        cumulative_percentage = data['cumulative_percentage']\n",
    "                        ax.plot(cumulative_percentage, cumulative_sum,\n",
    "                               color=dimension_color, linewidth=1.0, alpha=0.6)\n",
    "            else:\n",
    "                # 如果没有数据，设置默认值\n",
    "                all_curves_max = 0\n",
    "                all_curves_min = 0\n",
    "            \n",
    "            ax.set_xlim(0, 100)\n",
    "            ax.set_xlabel('Priority order in nation level (%)', fontweight='bold', fontsize=5)\n",
    "            ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            \n",
    "            if var_name == 'predicted_prob':\n",
    "                # Environmental: 除以1e6，保留1位小数，显示1e6\n",
    "                ax.set_ylim(0, all_curves_max * 1.1)\n",
    "                ax.yaxis.set_major_formatter(FuncFormatter(lambda x, pos: f'{x/1e6:.1f}'))\n",
    "                ax.set_ylabel('cumulative score (Unitless, $\\\\times 10^6$)', fontsize=6, fontweight='bold')\n",
    "                yticks = np.linspace(0, all_curves_max * 1.03, 5)\n",
    "                ax.set_yticks(yticks)\n",
    "            elif var_name == 'Expectation_net_benefit':\n",
    "                ax.set_ylim(0, all_curves_max * 1.1)\n",
    "                ax.yaxis.set_major_formatter(FuncFormatter(lambda x, pos: f'{x/1e9:.1f}'))\n",
    "                ax.set_ylabel('cumulative mitigation (Gt CO$_2$)', fontsize=6, fontweight='bold')\n",
    "                yticks = np.linspace(0, all_curves_max * 1.03, 5)\n",
    "                ax.set_yticks(yticks)\n",
    "            elif var_name == 'net_npv_usd':\n",
    "                y_range = all_curves_max - all_curves_min\n",
    "                if y_range == 0:\n",
    "                    y_range = abs(all_curves_max) * 0.1 if all_curves_max != 0 else 1\n",
    "                y_min = all_curves_min - y_range * 0.1\n",
    "                y_max = all_curves_max + y_range * 0.1\n",
    "                ax.set_ylim(y_min, y_max * 1.1)\n",
    "                ax.set_ylabel('cumulative revenue (Billion USD)', fontsize=6, fontweight='bold', labelpad=1.2)\n",
    "                \n",
    "                # 生成yticks，并确保0会被标注出来\n",
    "                yticks = np.linspace(y_min, y_max*1.03, 5)\n",
    "                if not np.isclose(yticks, 0).any() and (0 > yticks.min()) and (0 < yticks.max()):\n",
    "                    yticks = np.sort(np.append(yticks, 0))\n",
    "                ax.set_yticks(yticks)\n",
    "                \n",
    "                def billion_formatter(x, pos):\n",
    "                    if np.isclose(x, 0):\n",
    "                        return '0'\n",
    "                    return f'{x/1e9:.1f}'\n",
    "                ax.yaxis.set_major_formatter(FuncFormatter(billion_formatter))\n",
    "            else:\n",
    "                # 默认格式\n",
    "                ax.set_ylabel(f'{var_label}', fontweight='bold', fontsize=8)\n",
    "            \n",
    "            \n",
    "            arrow_x = FancyArrowPatch(\n",
    "                posA=(ax.get_xlim()[1] * 1.0, 0),\n",
    "                posB=(ax.get_xlim()[1] * 1.03, 0),\n",
    "                transform=ax.get_xaxis_transform(),\n",
    "                arrowstyle='simple',\n",
    "                color='black', linewidth=0, mutation_scale=8, zorder=20\n",
    "            )\n",
    "            arrow_x.set_clip_on(False)\n",
    "            ax.add_patch(arrow_x)\n",
    "            \n",
    "            y_lim = ax.get_ylim()\n",
    "            arrow_y = FancyArrowPatch(\n",
    "                posA=(0, y_lim[1] * 1.0),\n",
    "                posB=(0, y_lim[1] * 1.03),\n",
    "                transform=ax.get_yaxis_transform(),\n",
    "                arrowstyle='simple',\n",
    "                color='black', linewidth=0, mutation_scale=8, zorder=20\n",
    "            )\n",
    "            arrow_y.set_clip_on(False)\n",
    "            ax.add_patch(arrow_y)\n",
    "            \n",
    "            # 设置刻度参数\n",
    "            ax.tick_params(axis='x', which='major', length=2.5, width=0.5, pad=2, labelsize=5)\n",
    "            ax.tick_params(axis='y', which='major', length=2.5, width=0.5, pad=2, labelsize=5)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 在fig层面添加面板标签 (a, b, c, d) - 为每个solution的figure添加\n",
    "        panel_label = chr(97 + sol_idx)  # 97是'a'的ASCII码，依次为a, b, c, d\n",
    "        fig.text(0.01, 0.99, panel_label, ha='left', va='top', fontsize=7, fontweight='bold',\n",
    "               transform=fig.transFigure,\n",
    "               bbox=dict(facecolor='white', edgecolor='none', alpha=0.7, pad=0.2, lw=0), \n",
    "               zorder=100)\n",
    "        \n",
    "        if target_states is not None and len(legend_handles) > 0:\n",
    "            # 创建图例，确保显示线型\n",
    "            fig.legend(legend_handles, legend_labels, \n",
    "                       loc='upper center', \n",
    "                       bbox_to_anchor=(0.5, 1.0),\n",
    "                       ncol=len(legend_labels),\n",
    "                       frameon=False,\n",
    "                       fontsize=5,\n",
    "                       columnspacing=1.0,  \n",
    "                       handlelength=3.0,   \n",
    "                       handletextpad=0.5)  \n",
    "            # 调整subplots位置，为图例留出空间\n",
    "            plt.subplots_adjust(top=0.88)\n",
    "            # 在target_states场景下，文本位置需要调整（因为图例占用了顶部空间）\n",
    "            fig.text(0.98, 0.95, f'by {solution_type}', fontsize=5, fontweight='bold', \n",
    "                    va='top', ha='right', transform=fig.transFigure, zorder=100)\n",
    "        else:\n",
    "            # 在all_states场景下，文本在正常位置\n",
    "            fig.text(0.98, 0.98, f'by {solution_type}', fontsize=5, fontweight='bold', \n",
    "                    va='top', ha='right', transform=fig.transFigure, zorder=100)\n",
    "\n",
    "\n",
    "        # 保存图片\n",
    "        if target_states is not None:\n",
    "            output_path = os.path.join(output_dir, f'Figure_state_cumulative_target_{solution_type}.png')\n",
    "        else:\n",
    "            output_path = os.path.join(output_dir, f'Figure_state_cumulative_all_{solution_type}.png')\n",
    "        \n",
    "        fig.savefig(output_path, dpi=300, format='png')\n",
    "        print(f\"已保存: {output_path}\")\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"所有图形已保存到: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "17f6b194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始计算州级累积曲线...\n",
      "=== 开始州级别累积积分统计分析（简化版）===\n",
      "正在处理数据...\n",
      "正在添加州标签...\n",
      "发现 48 个州\n",
      "正在处理排序方案: Environmental suitability\n",
      "  处理维度: Environmental_sustainability\n",
      "  处理维度: Emission_mitigation_ability\n",
      "  处理维度: Economic_feasibility\n",
      "正在处理排序方案: Emission mitigation ability\n",
      "  处理维度: Environmental_sustainability\n",
      "  处理维度: Emission_mitigation_ability\n",
      "  处理维度: Economic_feasibility\n",
      "正在处理排序方案: Economic viability\n",
      "  处理维度: Environmental_sustainability\n",
      "  处理维度: Emission_mitigation_ability\n",
      "  处理维度: Economic_feasibility\n",
      "正在处理排序方案: 3E-synergy\n",
      "  处理维度: Environmental_sustainability\n",
      "  处理维度: Emission_mitigation_ability\n",
      "  处理维度: Economic_feasibility\n",
      "正在格式化结果...\n",
      "\n",
      "=== 州级别累积积分统计完成 ===\n",
      "总州数: 48\n",
      "总记录数: 192\n",
      "每个州有 4 种排序方案\n",
      "\n",
      "前10个州的WCCD方案结果:\n",
      " State_name  Environmental_sustainability  Emission_mitigation_ability  Economic_feasibility\n",
      "    Alabama                  52292.254042                 2.749749e+08         -3.922319e+09\n",
      "    Arizona                  26106.905653                 1.797899e+08          3.114122e+10\n",
      "   Arkansas                  40071.533379                 2.008081e+08         -8.925211e+09\n",
      " California                 194561.995308                 1.343924e+09          1.827685e+11\n",
      "   Colorado                  63915.172019                 4.868194e+08          6.803924e+10\n",
      "Connecticut                    220.571464                 9.894389e+05         -1.407782e+08\n",
      "   Delaware                  15008.815635                 7.307513e+07         -3.381845e+09\n",
      "    Florida                  80110.089375                 4.118637e+08          1.804684e+09\n",
      "    Georgia                 152560.459047                 7.986321e+08         -6.854899e+09\n",
      "      Idaho                  37684.767522                 3.074283e+08          2.173729e+10\n"
     ]
    }
   ],
   "source": [
    "# 定义变量和方案\n",
    "variables = [\n",
    "    ('predicted_prob', 'Environmental_sustainability'),\n",
    "    ('Expectation_net_benefit', 'Emission_mitigation_ability'), \n",
    "    ('net_npv_usd', 'Economic_feasibility')\n",
    "]\n",
    "\n",
    "solution_types = ['Environmental suitability', 'Emission mitigation ability', 'Economic viability', '3E-synergy']\n",
    "target_states = ['California', 'Texas', 'Georgia', 'Indiana', 'New York']\n",
    "\n",
    "# 执行计算（不绘制，使用新的绘图函数）\n",
    "print(\"开始计算州级累积曲线...\")\n",
    "results_df, state_curves_data = calculate_state_integration_analysis_simplified(\n",
    "    merged_data_for_analysis, \n",
    "    us_states_4326,\n",
    "    plot_curves=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "1b803803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 绘制所有州的累积曲线 ===\n",
      "正在绘制排序方案: Environmental suitability\n",
      "已保存: Supplymentary_figure\\Figure_state_cumulative_all_Environmental suitability.png\n",
      "正在绘制排序方案: Emission mitigation ability\n",
      "已保存: Supplymentary_figure\\Figure_state_cumulative_all_Emission mitigation ability.png\n",
      "正在绘制排序方案: Economic viability\n",
      "已保存: Supplymentary_figure\\Figure_state_cumulative_all_Economic viability.png\n",
      "正在绘制排序方案: 3E-synergy\n",
      "已保存: Supplymentary_figure\\Figure_state_cumulative_all_3E-synergy.png\n",
      "所有图形已保存到: Supplymentary_figure\n"
     ]
    }
   ],
   "source": [
    "# 绘制所有州的累积曲线\n",
    "print(\"\\n=== 绘制所有州的累积曲线 ===\")\n",
    "create_state_cumulative_curves_publication(\n",
    "    state_curves_data, \n",
    "    variables, \n",
    "    solution_types,\n",
    "    target_states=None,  # 所有州\n",
    "    output_dir='Supplymentary_figure'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "369361e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 绘制目标州的累积曲线 ===\n",
      "正在绘制排序方案: Environmental suitability\n",
      "已保存: Supplymentary_figure\\Figure_state_cumulative_target_Environmental suitability.png\n",
      "正在绘制排序方案: Emission mitigation ability\n",
      "已保存: Supplymentary_figure\\Figure_state_cumulative_target_Emission mitigation ability.png\n",
      "正在绘制排序方案: Economic viability\n",
      "已保存: Supplymentary_figure\\Figure_state_cumulative_target_Economic viability.png\n",
      "正在绘制排序方案: 3E-synergy\n",
      "已保存: Supplymentary_figure\\Figure_state_cumulative_target_3E-synergy.png\n",
      "所有图形已保存到: Supplymentary_figure\n"
     ]
    }
   ],
   "source": [
    "# 绘制目标州的累积曲线\n",
    "print(\"\\n=== 绘制目标州的累积曲线 ===\")\n",
    "create_state_cumulative_curves_publication(\n",
    "    state_curves_data, \n",
    "    variables, \n",
    "    solution_types,\n",
    "    target_states=target_states,  # 目标州\n",
    "    output_dir='Supplymentary_figure'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
