# -*- coding: utf-8 -*-
"""
æäº¤æ‰€æœ‰æ•æ„Ÿæ€§åˆ†æä»»åŠ¡åˆ°Google Cloud AI Platform
ç”Ÿæˆ18ä¸ªå‚æ•°ç»„åˆï¼Œæäº¤å¹¶è¡Œä»»åŠ¡
"""

import os
import json
import time
from pathlib import Path
from google.cloud import aiplatform
from google.cloud import storage

# æ·»åŠ é¡¹ç›®è·¯å¾„
script_dir = Path(__file__).parent
project_root = script_dir.parent.parent
import sys
sys.path.insert(0, str(project_root))

# å¯¼å…¥å·¥å…·å‡½æ•°
sys.path.insert(0, str(script_dir))
from sensitivity_utils import (
    generate_l18_orthogonal_array,
    map_orthogonal_to_params
)


def submit_jobs_to_gcp(
    project_id,
    region,
    bucket_name,
    image_uri,
    config
):
    """æäº¤æ‰€æœ‰ä»»åŠ¡åˆ°GCP AI Platform"""
    
    # åˆå§‹åŒ–AI Platform
    aiplatform.init(
    project=project_id, 
    location=region,
    staging_bucket=f'gs://{bucket_name}'  
)
    
    # ç”Ÿæˆå‚æ•°ç»„åˆ
    sensitivity_configs = {
        "d_model": [32, 64, 128],
        "num_layers": [4, 8, 12],
        "resnet_width": [64, 128, 256],
        "resnet_depth": [3, 6, 9],
        "learning_rate": [0.0001, 0.001, 0.01],
        "dropout_rate": [0.1, 0.3, 0.5],
    }
    
    orthogonal_array = generate_l18_orthogonal_array()
    param_combinations = map_orthogonal_to_params(orthogonal_array, sensitivity_configs)
    
    print(f"âœ… ç”Ÿæˆ {len(param_combinations)} ä¸ªå‚æ•°ç»„åˆ")
    
    # å‡†å¤‡é…ç½®æ–‡ä»¶
    full_config = {
        'param_combinations': param_combinations,
        **config
    }
    
    # ä¸Šä¼ é…ç½®æ–‡ä»¶åˆ°GCS
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    config_json = json.dumps(full_config, indent=2, default=str)
    blob = bucket.blob('configs/sensitivity_config.json')
    blob.upload_from_string(config_json, content_type='application/json')
    config_gcs_path = f'gs://{bucket_name}/configs/sensitivity_config.json'
    print(f"âœ… é…ç½®æ–‡ä»¶å·²ä¸Šä¼ : {config_gcs_path}")
    
    # ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºæ‰€æœ‰ä»»åŠ¡å¯¹è±¡ï¼ˆä¸æäº¤ï¼‰
    print(f"\n{'='*80}")
    print(f"åˆ›å»º {len(param_combinations)} ä¸ªä»»åŠ¡å¯¹è±¡...")
    print(f"{'='*80}")
    
    jobs = []
    job_ids = []
    
    for i in range(1, len(param_combinations) + 1):
        exp_id = f"E{i}"
        job_name = f'sensitivity-analysis-{exp_id}'
        
        try:
            job = aiplatform.CustomJob(
                display_name=job_name,
                worker_pool_specs=[
                    {
                        'machine_spec': {
                            'machine_type': 'n1-standard-8',
                            'accelerator_type': 'NVIDIA_TESLA_T4',
                            'accelerator_count': 1
                        },
                        'replica_count': 1,
                        'container_spec': {
                            'image_uri': image_uri,
                            'args': [
                                '--exp_id', str(i),
                                '--config', config_gcs_path,
                                '--data_dir', '/data',
                                '--output_dir', '/output'
                            ]
                        }
                    }
                ],
                project=project_id,
                location=region
            )
            jobs.append((i, exp_id, job_name, job))
            print(f"âœ… ä»»åŠ¡ {i}/{len(param_combinations)} å¯¹è±¡å·²åˆ›å»º: {job_name}")
        except Exception as e:
            print(f"âŒ ä»»åŠ¡ {i} åˆ›å»ºå¤±è´¥: {e}")
            job_ids.append({
                'exp_id': exp_id,
                'job_name': job_name,
                'error': f'åˆ›å»ºå¤±è´¥: {str(e)}'
            })
    
    # ç¬¬äºŒæ­¥ï¼šä¸€æ¬¡æ€§æäº¤æ‰€æœ‰ä»»åŠ¡ï¼ˆå¹¶è¡Œï¼‰
    print(f"\n{'='*80}")
    print(f"ä¸€æ¬¡æ€§æäº¤ {len(jobs)} ä¸ªä»»åŠ¡åˆ°GPUé›†ç¾¤ï¼ˆå¹¶è¡Œè¿è¡Œï¼‰...")
    print(f"{'='*80}")
    
    submitted_count = 0
    failed_count = 0
    
    for i, exp_id, job_name, job in jobs:
        try:
            # ä½¿ç”¨ run(sync=False) å¼‚æ­¥æäº¤ï¼Œä¸ä¼šé˜»å¡ï¼Œä»»åŠ¡ä¼šå¹¶è¡Œè¿è¡Œ
            # sync=False è¡¨ç¤ºä¸ç­‰å¾…ä»»åŠ¡å®Œæˆï¼Œç«‹å³è¿”å›
            job.run(sync=False)
            
            # ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©èµ„æºåˆ›å»ºå®Œæˆ
            time.sleep(0.5)
            
            # å°è¯•è·å–ä»»åŠ¡èµ„æºåç§°ï¼ˆå¯èƒ½éœ€è¦é‡è¯•ï¼‰
            resource_name = None
            job_id = None
            max_retries = 3
            for retry in range(max_retries):
                try:
                    resource_name = job.resource_name
                    if resource_name:
                        job_id = resource_name.split('/')[-1]
                        break
                except (AttributeError, ValueError) as e:
                    if retry < max_retries - 1:
                        time.sleep(0.3)  # ç­‰å¾…åé‡è¯•
                        continue
                    else:
                        # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­
                        print(f"    âš ï¸ æ— æ³•è·å–èµ„æºåç§°ï¼Œä½†ä»»åŠ¡å¯èƒ½å·²æäº¤")
            
            job_ids.append({
                'exp_id': exp_id,
                'job_name': job_name,
                'resource_name': resource_name or 'pending',
                'job_id': job_id or 'pending',
                'status': 'submitted' if resource_name else 'submitted_pending'
            })
            
            submitted_count += 1
            if job_id:
                print(f"âœ… [{submitted_count}/{len(jobs)}] ä»»åŠ¡å·²æäº¤: {job_name} (ID: {job_id})")
            else:
                print(f"âœ… [{submitted_count}/{len(jobs)}] ä»»åŠ¡å·²æäº¤: {job_name} (èµ„æºåˆ›å»ºä¸­...)")
            
        except Exception as e:
            failed_count += 1
            error_msg = str(e)
            print(f"âŒ [{i}/{len(jobs)}] ä»»åŠ¡æäº¤å¤±è´¥: {job_name}")
            print(f"   é”™è¯¯: {error_msg}")
            
            job_ids.append({
                'exp_id': exp_id,
                'job_name': job_name,
                'error': error_msg,
                'status': 'failed'
            })
        
        # çŸ­æš‚å»¶è¿Ÿé¿å…APIé™æµ
        if i < len(jobs):
            time.sleep(0.1)  # å‡å°‘å»¶è¿Ÿï¼Œå› ä¸ºä¸Šé¢å·²ç»ç­‰å¾…äº†0.5ç§’
    
    # ä¿å­˜ä»»åŠ¡ID
    jobs_file = script_dir / 'submitted_jobs.json'
    with open(jobs_file, 'w') as f:
        json.dump(job_ids, f, indent=2)
    
    print(f"\n{'='*80}")
    print(f"âœ… ä»»åŠ¡æäº¤å®Œæˆ")
    print(f"  - æˆåŠŸæäº¤: {submitted_count}/{len(jobs)} ä¸ªä»»åŠ¡")
    print(f"  - æäº¤å¤±è´¥: {failed_count}/{len(jobs)} ä¸ªä»»åŠ¡")
    print(f"  - ä»»åŠ¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {jobs_file}")
    print(f"\nğŸ“Š æ‰€æœ‰ä»»åŠ¡å°†å¹¶è¡Œè¿è¡Œï¼Œåˆ©ç”¨ {len(jobs)} ä¸ªGPU")
    print(f"\nç›‘æ§ä»»åŠ¡çŠ¶æ€:")
    print(f"  gcloud ai custom-jobs list --region={region} --project={project_id}")
    print(f"\næŸ¥çœ‹å•ä¸ªä»»åŠ¡æ—¥å¿—:")
    for job_info in job_ids:
        if 'job_id' in job_info and job_info.get('status') == 'submitted':
            print(f"  gcloud ai custom-jobs describe {job_info['job_id']} --region={region} --project={project_id}")
            break  # åªæ˜¾ç¤ºä¸€ä¸ªç¤ºä¾‹
    print(f"{'='*80}\n")
    
    return job_ids


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='æäº¤ä»»åŠ¡åˆ°GCP AI Platform')
    parser.add_argument('--project_id', type=str, required=True, help='GCPé¡¹ç›®ID')
    parser.add_argument('--region', type=str, default='us-central1', help='GCPåŒºåŸŸ')
    parser.add_argument('--bucket', type=str, required=True, help='GCS bucketåç§°')
    parser.add_argument('--image', type=str, required=True, help='å®¹å™¨é•œåƒURI (gcr.io/...)')
    
    args = parser.parse_args()
    
    # è®­ç»ƒé…ç½®
    config = {
        'negative_strategy': 'generation',
        'negative_ratio': 1,
        'test_size': 0.2,
        'val_size': 0.2,
        'epochs': 80,
        'batch_size': 256,
        'random_state': 42,
        'plot_learning_curve': True,
        'learning_curve_epochs': 20,
        'save_models': True,
        'bucket_name': args.bucket
    }
    
    submit_jobs_to_gcp(
        project_id=args.project_id,
        region=args.region,
        bucket_name=args.bucket,
        image_uri=args.image,
        config=config
    )