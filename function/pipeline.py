# -*- coding: utf-8 -*-
"""
å®Œæ•´è®­ç»ƒç®¡é“æ¨¡å—
åŒ…å«ä»GMMè®­ç»ƒåˆ°æ¨¡å‹é¢„æµ‹çš„å®Œæ•´æµç¨‹
"""

from __future__ import annotations

import os
import pandas as pd
import joblib

# å¯¼å…¥å…¶ä»–æ¨¡å—
from .gmm_training import select_and_train_gmm
from .negative_sampling import generate_negative_samples_unified
from .training import train_and_evaluate_model, train_multiple_models
from .evaluation import plot_complete_pipeline_results

# å¯¼å…¥è¯Šæ–­æ¨¡å—ï¼ˆå¯é€‰ï¼‰
try:
    from .model_diagnostics import (
        diagnose_transformer_model,
        diagnose_mlp_model,
        diagnose_rf_model,
        pu_evaluation_from_results
    )
    MODEL_DIAGNOSTICS_AVAILABLE = True
except ImportError:
    MODEL_DIAGNOSTICS_AVAILABLE = False
    print("âš ï¸ Some function modules not available")


def run_correct_training_pipeline(
    df_positive, df_prediction_pool, features_no_coords,
    negative_strategy='selection',
    negative_ratio=1.0,
    sampling_strategy='pit_based',
    difficulty_levels=3,
    augmentation_ratio=1.0,
    selection_weight='gmm_score',
    test_size=0.2,
    val_size=0.2,
    epochs=50,
    batch_size=32,
    random_state=42,
    hidden_layers=[128, 64, 32],
    dropout_rate=0.3,
    learning_rate=0.001,
    plot_learning_curve=True,
    learning_curve_epochs=30,
    model_type='transformer',
    train_mode='single',
    models_to_train=['transformer', 'mlp', 'rf'],
    transformer_config={'d_model': 64, 'num_heads': 4, 'num_layers': 2},
    rf_config={'n_estimators': 100, 'max_depth': 15},
    resnet_layers=[128, 128, 64],
    run_shap=False
):
    """
    å®Œæ•´çš„è®­ç»ƒç®¡é“ï¼šGMM + è´Ÿæ ·æœ¬é‡‡æ · + æ¨¡å‹è®­ç»ƒ + é¢„æµ‹
    
    Parameters:
    -----------
    train_mode : "single" | "multiple"
        - "single": è®­ç»ƒå•ä¸ªæ¨¡å‹ï¼ˆé»˜è®¤transformerï¼‰
        - "multiple": è®­ç»ƒå¤šä¸ªæ¨¡å‹å¹¶å¯¹æ¯”
    model_type : str (train_mode="single"æ—¶ä½¿ç”¨)
    models_to_train : list (train_mode="multiple"æ—¶ä½¿ç”¨)
    """
    print("=" * 80)
    print("æ­£ç¡®çš„è®­ç»ƒç®¡é“ï¼šåˆ†å±‚è´Ÿæ ·æœ¬é‡‡æ ·çš„å®Œæ•´æµç¨‹")
    print("=" * 80)
    
    try:
        # æ­¥éª¤1: å°è¯•åŠ è½½å·²è®­ç»ƒçš„GMMæ¨¡å‹ï¼Œå¦åˆ™é‡æ–°è®­ç»ƒ
        print("\næ­¥éª¤1: åŠ è½½æˆ–è®­ç»ƒGMMæ¨¡å‹ç”¨äºç¯å¢ƒç›¸ä¼¼åº¦è¯„ä¼°")
        from pathlib import Path

        def find_project_root(start_path=None):
            """æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŒ…å«dataå’Œfunctionç›®å½•çš„ç›®å½•ï¼‰"""
            if start_path is None:
                start_path = Path.cwd()
            
            current = Path(start_path).resolve()
            for _ in range(5):  # æœ€å¤šå‘ä¸ŠæŸ¥æ‰¾5å±‚
                if (current / 'data').exists() and (current / 'function').exists():
                    return current
                parent = current.parent
                if parent == current:
                    break
                current = parent
            return Path.cwd().parent

        project_root = find_project_root()
        print(f"[GMM] å½“å‰é¡¹ç›®æ ¹ç›®å½•æ¨æ–­ä¸º: {project_root}")

        gmm_model_files = []
        gmm_model_candidates = []
        for filename in os.listdir(project_root):
            if filename.startswith('gmm_model_') and filename.endswith('c_fixed.pkl'):
                gmm_model_candidates.append(filename)
        if gmm_model_candidates:
            gmm_model_candidates.sort(key=lambda x: os.path.getmtime(project_root / x), reverse=True)
            gmm_model_files = [gmm_model_candidates[0]]
        
        gmm_pipeline = None

        if gmm_model_files:
            latest_model_file = gmm_model_files[-1]
            full_model_path = project_root / latest_model_file
            try:
                print(f"ğŸ” å‘ç°å·²ä¿å­˜çš„GMMæ¨¡å‹æ–‡ä»¶: {full_model_path}")
                print(f"ğŸ“‚ å°è¯•åŠ è½½æ¨¡å‹...")
                
                gmm_pipeline = joblib.load(full_model_path)
                
                # éªŒè¯åŠ è½½çš„æ¨¡å‹ç»“æ„
                if (hasattr(gmm_pipeline, 'named_steps') and 
                    'preprocessor' in gmm_pipeline.named_steps and 
                    'gmm' in gmm_pipeline.named_steps):
                    
                    # å¿«é€ŸéªŒè¯æ¨¡å‹æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œ
                    test_sample = df_positive[features_no_coords].iloc[:5]
                    _ = gmm_pipeline.named_steps['preprocessor'].transform(test_sample)
                    
                    print(f"âœ… æˆåŠŸåŠ è½½GMMæ¨¡å‹: {latest_model_file}")
                    print(f"   æ¨¡å‹ç»„ä»¶æ•°: {gmm_pipeline.named_steps['gmm'].n_components}")
                    print(f"   åæ–¹å·®ç±»å‹: {gmm_pipeline.named_steps['gmm'].covariance_type}")
                    
                else:
                    raise ValueError("æ¨¡å‹ç»“æ„ä¸å®Œæ•´")
                    
            except Exception as e:
                print(f"âš ï¸ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
                print("ğŸ”„ å°†é‡æ–°è®­ç»ƒGMMæ¨¡å‹...")
                gmm_pipeline = None
        
        # å¦‚æœåŠ è½½å¤±è´¥æˆ–æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œåˆ™é‡æ–°è®­ç»ƒ
        if gmm_pipeline is None:
            print("ğŸš€ å¼€å§‹è®­ç»ƒæ–°çš„GMMæ¨¡å‹...")
            gmm_pipeline = select_and_train_gmm(df_positive[features_no_coords])
            
            if gmm_pipeline is None:
                raise ValueError("GMMæ¨¡å‹è®­ç»ƒå¤±è´¥")
        
        # æå–é¢„å¤„ç†å™¨
        if hasattr(gmm_pipeline, 'named_steps') and 'preprocessor' in gmm_pipeline.named_steps:
            gmm_preprocessor = gmm_pipeline.named_steps['preprocessor']
        else:
            gmm_preprocessor = gmm_pipeline
        
        # æ­¥éª¤2: è´Ÿæ ·æœ¬ç”Ÿæˆï¼ˆä½¿ç”¨ç»Ÿä¸€æ¥å£ï¼‰
        print(f"\næ­¥éª¤2: è´Ÿæ ·æœ¬ç”Ÿæˆ - ç­–ç•¥: {negative_strategy}")
        
        df_negative_samples, df_remaining_prediction, df_combined_training = \
            generate_negative_samples_unified(
                strategy_type=negative_strategy,
                df_positive=df_positive,
                df_prediction_pool=df_prediction_pool,
                features=features_no_coords,
                gmm_pipeline=gmm_pipeline,
                negative_ratio=negative_ratio,
                random_state=random_state,
                sampling_strategy=sampling_strategy,
                difficulty_levels=difficulty_levels,
                augmentation_ratio=augmentation_ratio,
                selection_weight=selection_weight
            )
        
        if df_combined_training is None:
            raise ValueError("è´Ÿæ ·æœ¬ç”Ÿæˆå¤±è´¥")
        
        # æ­¥éª¤3: è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹
        print("\næ­¥éª¤3: è®­ç»ƒæ·±åº¦å­¦ä¹ åˆ†ç±»æ¨¡å‹")
        
        if train_mode == "multiple":
            training_results = train_multiple_models(
                df_combined_training, features_no_coords, gmm_preprocessor,
                models_to_train=models_to_train,
                test_size=test_size, val_size=val_size, epochs=epochs,
                batch_size=batch_size, random_state=random_state,
                hidden_layers=hidden_layers, dropout_rate=dropout_rate,
                learning_rate=learning_rate,
                plot_learning_curve=plot_learning_curve,
                learning_curve_epochs=learning_curve_epochs,
                transformer_config=transformer_config,
                rf_config=rf_config,
                resnet_layers=resnet_layers
            )
            
            if training_results is None:
                raise ValueError("å¤šæ¨¡å‹è®­ç»ƒå¤±è´¥")
            
            # ä½¿ç”¨æœ€ä½³æ¨¡å‹
            best_model_name = training_results['best_model']
            model_result = training_results['results'][best_model_name]
            
            model = model_result['model']
            retrained_preprocessor = model_result['preprocessor']
            
            print(f"\nä½¿ç”¨æœ€ä½³æ¨¡å‹ {best_model_name.upper()} è¿›è¡Œé¢„æµ‹")
            
        else:
            training_results = train_and_evaluate_model(
                df_combined_training, features_no_coords, gmm_preprocessor,
                test_size=test_size, val_size=val_size, epochs=epochs,
                batch_size=batch_size, random_state=random_state,
                hidden_layers=hidden_layers, dropout_rate=dropout_rate,
                learning_rate=learning_rate,
                plot_learning_curve=plot_learning_curve,
                learning_curve_epochs=learning_curve_epochs,
                model_type=model_type,
                transformer_config=transformer_config,
                rf_config=rf_config,
                resnet_layers=resnet_layers
            )
            
            if training_results is None:
                raise ValueError("æ¨¡å‹è®­ç»ƒå¤±è´¥")
            
            model = training_results['model']
            retrained_preprocessor = training_results['preprocessor']
        
        # æ­¥éª¤4: å¯¹å‰©ä½™é¢„æµ‹æ ·æœ¬è¿›è¡Œé¢„æµ‹
        print("\næ­¥éª¤4: å¯¹å‰©ä½™é¢„æµ‹æ ·æœ¬è¿›è¡Œé¢„æµ‹")
        X_remaining_processed = retrained_preprocessor.transform(df_remaining_prediction[features_no_coords])
        remaining_pred_prob = model.predict(X_remaining_processed, verbose=0).ravel()
        remaining_pred_binary = (remaining_pred_prob > 0.5).astype(int)
        
        print(f"å‰©ä½™æ ·æœ¬é¢„æµ‹å®Œæˆ: {len(remaining_pred_prob)} ä¸ªæ ·æœ¬")
        print(f"é¢„æµ‹ä¸ºæ­£ç±»çš„æ•°é‡: {remaining_pred_binary.sum()}")
        print(f"é¢„æµ‹ä¸ºæ­£ç±»çš„æ¯”ä¾‹: {remaining_pred_binary.mean():.3f}")
        print(f"å¹³å‡é¢„æµ‹æ¦‚ç‡: {remaining_pred_prob.mean():.3f}")
        
        # æ­¥éª¤5: åˆå¹¶è´Ÿæ ·æœ¬å’Œé¢„æµ‹ç»“æœ
        print("\næ­¥éª¤5: åˆå¹¶è´Ÿæ ·æœ¬å’Œé¢„æµ‹ç»“æœ")
        
        negative_results = df_negative_samples.copy()
        negative_results['predicted_label'] = 0
        negative_results['predicted_prob'] = 0.0
        negative_results['sample_type'] = 'negative_sample'
        
        prediction_results = df_remaining_prediction.copy()
        prediction_results['predicted_label'] = remaining_pred_binary
        prediction_results['predicted_prob'] = remaining_pred_prob
        prediction_results['sample_type'] = 'prediction'
        
        final_results = pd.concat([negative_results, prediction_results], ignore_index=True)
        
        print(f"æœ€ç»ˆç»“æœåˆå¹¶å®Œæˆ:")
        print(f"  è´Ÿæ ·æœ¬æ•°é‡: {len(negative_results)} (æ ‡ç­¾=0)")
        print(f"  é¢„æµ‹æ ·æœ¬æ•°é‡: {len(prediction_results)}")
        print(f"  æ€»æ ·æœ¬æ•°é‡: {len(final_results)}")
        print(f"  æœ€ç»ˆé¢„æµ‹ä¸ºæ­£ç±»çš„æ€»æ•°: {final_results['predicted_label'].sum()}")
        print(f"  æœ€ç»ˆé¢„æµ‹ä¸ºæ­£ç±»çš„æ¯”ä¾‹: {final_results['predicted_label'].mean():.3f}")
        
        shap_results = None
        pu_evaluation_results = None
        if run_shap and MODEL_DIAGNOSTICS_AVAILABLE:
            print("\næ­¥éª¤6: SHAPç‰¹å¾é‡è¦æ€§åˆ†æ")
            
            # å…¼å®¹å•æ¨¡å‹å’Œå¤šæ¨¡å‹æ¨¡å¼
            if train_mode == "single":
                X_test_data = training_results['splits']['X_test']
                y_test_data = training_results['splits']['y_test']
                model_type_for_shap = model_type
            else:
                X_test_data = training_results['splits']['X_test']
                y_test_data = training_results['splits']['y_test']
                model_type_for_shap = training_results['best_model']
            
            # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©æ­£ç¡®çš„è¯Šæ–­å‡½æ•°
            try:
                if model_type_for_shap == 'transformer':
                    shap_results = diagnose_transformer_model(
                        model=model, 
                        X_test=X_test_data,
                        y_test=y_test_data,
                        feature_names=features_no_coords,
                        model_name="Transformer"
                    )
                elif model_type_for_shap == 'mlp':
                    shap_results = diagnose_mlp_model(
                        model=model,
                        X_test=X_test_data,
                        y_test=y_test_data,
                        feature_names=features_no_coords,
                        model_name="MLP"
                    )
                elif model_type_for_shap == 'rf':
                    shap_results = diagnose_rf_model(
                        model=model,
                        X_test=X_test_data,
                        y_test=y_test_data,
                        feature_names=features_no_coords,
                        model_name="Random Forest"
                    )
                else:
                    print(f"âš ï¸ æœªçŸ¥æ¨¡å‹ç±»å‹: {model_type_for_shap}ï¼Œè·³è¿‡SHAPåˆ†æ")
                    shap_results = None
            except Exception as e:
                print(f"âŒ SHAPåˆ†æå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                shap_results = None

        # æ­¥éª¤6.5: PUå­¦ä¹ è¯„ä¼°
        if MODEL_DIAGNOSTICS_AVAILABLE:
            # ä¼°è®¡å…ˆéªŒæ¦‚ç‡ï¼ˆpiï¼‰
            high_prob_ratio = (remaining_pred_prob > 0.5).mean()
            pi_estimate = min(high_prob_ratio * 0.8, 0.30)

            # æ–¹å¼2: ä»GMMè¯„åˆ†ä¼°è®¡
            if 'gmm_score' in prediction_results.columns:
                high_env_ratio = (prediction_results['gmm_score'] > 0.5).mean()
                pi_estimate = max(pi_estimate, high_env_ratio * 0.6)
            
            print(f"\næ­¥éª¤6.5: PUå­¦ä¹ è¯„ä¼°")
            print(f"  ä¼°è®¡æ­£æ ·æœ¬å…ˆéªŒæ¦‚ç‡ï¼ˆÏ€ï¼‰: {pi_estimate:.1%}")

            # å‡†å¤‡ complete_results ç”¨äº PU è¯„ä¼°
            pu_complete_results = {
                'training_results': training_results,
                'model': model,
                'prediction_results': prediction_results,
                'config': {
                    'negative_ratio': negative_ratio,
                    'test_size': test_size,
                    'val_size': val_size,
                }
            }

            # å¦‚æœæ˜¯å¤šæ¨¡å‹æ¨¡å¼ï¼Œæ·»åŠ best_modelæ ‡è¯†
            if train_mode == "multiple":
                pu_complete_results['best_model'] = training_results['best_model']

            try:
                pu_results = pu_evaluation_from_results(
                    complete_results=pu_complete_results,
                    pi=pi_estimate,
                    negative_ratio=negative_ratio,
                    cost_fp=2.0,
                    cost_fn=1.0  
                )
                pu_evaluation_results = pu_results
                
                # æ‰“å°PUè¯„ä¼°æ‘˜è¦
                print(f"\nâœ… PUè¯„ä¼°å®Œæˆ:")
                print(f"  æ¨èé˜ˆå€¼: {pu_results['best']['thr']:.3f}")
                print(f"  å¬å›ç‡(R): {pu_results['best']['R']:.3f}")
                print(f"  æ£€æµ‹ç‡(D): {pu_results['best']['D']:.3f}")
                print(f"  è¯¯æŠ¥ç‡(FPR): {pu_results['best']['FPR']:.3f}")
                print(f"  F1â€²å¢å¼º: {pu_results['best']['F1_prime_enhanced']:.3f}")
                print(f"  å¯é æ€§: {pu_results['best']['reliability']}")
                print(f"\nğŸ’¡ å»ºè®®:")
                print(f"  {pu_results['recommendation']}")
                
            except Exception as e:
                print(f"âŒ PUè¯„ä¼°å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()

        # ç»˜å›¾
        if train_mode == "single":
            if 'history' in training_results:
                plot_complete_pipeline_results(
                    training_results, final_results, negative_results, prediction_results
                )
        else:
            best_model_name = training_results['best_model']
            best_model_result = training_results['results'][best_model_name]
            
            if best_model_name != 'rf' and 'history' in best_model_result:
                plot_complete_pipeline_results(
                    best_model_result, final_results, negative_results, prediction_results
                )
            else:
                print(f"\nâš ï¸ {best_model_name.upper()}æ¨¡å‹è·³è¿‡ç»˜å›¾ï¼ˆæ— è®­ç»ƒå†å²ï¼‰")
        
        # æ‰“å°å­¦ä¹ æ›²çº¿åˆ†ææ€»ç»“
        lc_analysis = training_results.get('learning_curve_results')  
        if plot_learning_curve and lc_analysis:
            print("\n" + "=" * 60)
            print("å­¦ä¹ æ›²çº¿åˆ†ææ€»ç»“:")
            print("=" * 60)
            
            if lc_analysis.get('overfitting_detected', False):
                print("âš ï¸ æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆ")
            else:
                print("âœ… æ¨¡å‹æ‹Ÿåˆç¨‹åº¦è‰¯å¥½")
            
            if lc_analysis.get('high_variance', False):
                print("âš ï¸ æ¨¡å‹æ–¹å·®è¾ƒé«˜ï¼Œå»ºè®®å¢åŠ è®­ç»ƒæ•°æ®æˆ–æ­£åˆ™åŒ–")
            else:
                print("âœ… æ¨¡å‹æ–¹å·®é€‚ä¸­")
            
            final_perf = lc_analysis.get('final_performance', 'N/A')
            if isinstance(final_perf, (int, float)) and final_perf != 'N/A':
                print(f"æœ€ç»ˆæ€§èƒ½: {final_perf:.4f}")
            else:
                print(f"æœ€ç»ˆæ€§èƒ½: {final_perf}")

        print("\n" + "=" * 80)
        print("âœ… åˆ†å±‚è´Ÿæ ·æœ¬é‡‡æ ·çš„è®­ç»ƒç®¡é“æ‰§è¡Œå®Œæˆï¼")
        print("=" * 80)

        splits = training_results.get('splits', {})

        return_result = {
            'model': model,
            'gmm_pipeline': gmm_pipeline,
            'training_results': training_results,
            'final_results': final_results,
            'negative_samples': negative_results,
            'prediction_results': prediction_results,
            'training_data': df_combined_training,
            'learning_curve_analysis': lc_analysis,
            'shap_analysis': shap_results,
            'pu_evaluation': pu_evaluation_results,
            'config': {
                'negative_ratio': negative_ratio,
                'sampling_strategy': sampling_strategy,
                'difficulty_levels': difficulty_levels,
                'test_size': test_size,
                'val_size': val_size,
                'plot_learning_curve': plot_learning_curve,
                'learning_curve_epochs': learning_curve_epochs,
                'random_state': random_state,
                'negative_strategy': negative_strategy,       
                'train_mode': train_mode,                   
                'model_type': model_type,                     
                'models_to_train': models_to_train if train_mode == 'multiple' else None,  
                'model_params': {
                    'hidden_layers': hidden_layers,
                    'dropout_rate': dropout_rate,
                    'learning_rate': learning_rate,
                    'epochs': epochs,
                    'batch_size': batch_size
                }
            },
            'X_train': splits.get('X_train'),
            'y_train': splits.get('y_train'),
            'X_val': splits.get('X_val'),
            'y_val': splits.get('y_val'),
            'X_test': splits.get('X_test'),
            'y_test': splits.get('y_test')
        }
        if train_mode == "multiple":
            return_result.update({
                'best_model': training_results['best_model'],
                'model_comparison': training_results['comparison'],
                'all_models': list(training_results['results'].keys())
            })
        return return_result
    except Exception as e:
        print(f"âŒ è®­ç»ƒç®¡é“æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

