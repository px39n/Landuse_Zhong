# -*- coding: utf-8 -*-
"""
æ¨¡å‹ä¿å­˜å’ŒåŠ è½½æ¨¡å—
åŒ…å«æ¨¡å‹ç®¡é“çš„ä¿å­˜å’ŒåŠ è½½åŠŸèƒ½
"""

from __future__ import annotations

import os
import json
import numpy as np
import joblib
from datetime import datetime
from sklearn.metrics import roc_curve, auc

# æ·±åº¦å­¦ä¹ åº“
try:
    import tensorflow as tf
    # ä½¿ç”¨ tf.keras è€Œä¸æ˜¯ from tensorflow import kerasï¼ˆé¿å…é€’å½’é”™è¯¯ï¼‰
    # TensorFlow 2.15 å…¼å®¹æ–¹å¼
    keras = tf.keras
    TENSORFLOW_AVAILABLE = True
except ImportError:
    TENSORFLOW_AVAILABLE = False
    print("âš ï¸ TensorFlow not available, some features will be disabled")
except RecursionError as e:
    # æ•è·é€’å½’é”™è¯¯ï¼ˆTensorFlow 2.15 çš„å·²çŸ¥é—®é¢˜ï¼‰
    TENSORFLOW_AVAILABLE = False
    print(f"âš ï¸ TensorFlow import recursion error: {e}")
    print("âš ï¸ This may be a TensorFlow 2.15 compatibility issue")
except Exception as e:
    # æ•è·æ‰€æœ‰å¼‚å¸¸ï¼Œä¸ä»…ä»…æ˜¯ ImportError
    TENSORFLOW_AVAILABLE = False
    print(f"âš ï¸ TensorFlow not available ({type(e).__name__}): {e}, some features will be disabled")


def save_complete_model_pipeline(
    gmm_pipeline, dl_model, retrained_preprocessor, training_results,
    final_results, negative_results, prediction_results,
    features, config, save_dir='models',
    model_name=None, model_type='transformer',
    negative_strategy='selection', train_mode='single',
    models_to_train=None, pu_evaluation=None
):
    """
    ä¿å­˜å®Œæ•´æ¨¡å‹ç®¡é“ï¼ˆå¢å¼ºç‰ˆï¼šåŒ…å«å‚æ•°éªŒè¯å’Œé”™è¯¯å¤„ç†ï¼‰
    """
    # å‚æ•°éªŒè¯
    if features is None:
        raise ValueError("features å‚æ•°ä¸èƒ½ä¸º None")
    if config is None:
        config = {}
    
    os.makedirs(save_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # æ„å»ºæ¨¡å‹æè¿°
    if train_mode == "multiple":
        model_desc = f"Multi-model ({', '.join(models_to_train) if models_to_train else 'unknown'})"
    else:
        model_desc = f"{model_type.title()}"
    
    # æ„å»ºé‡‡æ ·ç­–ç•¥æè¿°
    strategy_names = {
        'selection': 'Selection-based',
        'generation': 'Generation-based',
        'hybrid': 'Hybrid'
    }
    strategy_desc = strategy_names.get(negative_strategy, 'Unknown')
    
    # æ„å»ºæ–‡ä»¶å
    if model_name is None:
        model_name = f"landuse_{model_type}_{negative_strategy}_{train_mode}_{timestamp}"
    
    saved_files = {}  # è·Ÿè¸ªå·²ä¿å­˜çš„æ–‡ä»¶ï¼Œç”¨äºé”™è¯¯å›æ»š
    errors = []  # æ”¶é›†é”™è¯¯ä¿¡æ¯
    
    # 1. ä¿å­˜GMM Pipeline
    gmm_file = os.path.join(save_dir, f"{model_name}_gmm.pkl")
    try:
        if gmm_pipeline is None:
            raise ValueError("gmm_pipeline ä¸èƒ½ä¸º None")
        joblib.dump(gmm_pipeline, gmm_file)
        saved_files['gmm'] = gmm_file
        print(f"âœ… GMM Pipeline å·²ä¿å­˜: {gmm_file}")
    except Exception as e:
        error_msg = f"ä¿å­˜ GMM Pipeline å¤±è´¥: {e}"
        print(f"âŒ {error_msg}")
        errors.append(error_msg)
        gmm_file = None
    
    # 2. ä¿å­˜æ·±åº¦å­¦ä¹ æ¨¡å‹
    dl_file = os.path.join(save_dir, f"{model_name}_dl.h5")
    try:
        if dl_model is None:
            raise ValueError("dl_model ä¸èƒ½ä¸º None")
        
        if model_type != 'rf':
            if not TENSORFLOW_AVAILABLE:
                raise ImportError("TensorFlow not available for saving model")
            
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ç¼–è¯‘ï¼ˆæŸäº›ç‰ˆæœ¬éœ€è¦ï¼‰
            try:
                if hasattr(dl_model, 'optimizer') and dl_model.optimizer is None:
                    print("âš ï¸ æ¨¡å‹æœªç¼–è¯‘ï¼Œå°è¯•ä¿å­˜æ¶æ„å’Œæƒé‡...")
                
                # TensorFlow 2.15+ ä½¿ç”¨ SavedModel æ ¼å¼æ›´å…¼å®¹
                # ä½†ä¸ºäº†å‘åå…¼å®¹ï¼Œä»ä½¿ç”¨ .h5 æ ¼å¼
                dl_model.save(dl_file, save_format='h5')
                saved_files['dl'] = dl_file
                print(f"âœ… æ·±åº¦å­¦ä¹ æ¨¡å‹å·²ä¿å­˜: {dl_file}")
            except Exception as save_error:
                # å¦‚æœ .h5 æ ¼å¼å¤±è´¥ï¼Œå°è¯• SavedModel æ ¼å¼
                try:
                    savedmodel_dir = dl_file.replace('.h5', '_savedmodel')
                    dl_model.save(savedmodel_dir)
                    dl_file = savedmodel_dir
                    saved_files['dl'] = dl_file
                    print(f"âœ… æ·±åº¦å­¦ä¹ æ¨¡å‹å·²ä¿å­˜ (SavedModelæ ¼å¼): {dl_file}")
                except Exception as save_error2:
                    raise save_error  # æŠ›å‡ºåŸå§‹é”™è¯¯
        else:
            # Random Forest æ¨¡å‹
            joblib.dump(dl_model, dl_file)
            saved_files['dl'] = dl_file
            print(f"âœ… Random Forest æ¨¡å‹å·²ä¿å­˜: {dl_file}")
    except Exception as e:
        error_msg = f"ä¿å­˜æ·±åº¦å­¦ä¹ æ¨¡å‹å¤±è´¥: {e}"
        print(f"âŒ {error_msg}")
        errors.append(error_msg)
        dl_file = None
    
    # 3. ä¿å­˜é¢„å¤„ç†å™¨
    preprocessor_file = os.path.join(save_dir, f"{model_name}_preprocessor.pkl")
    try:
        if retrained_preprocessor is None:
            raise ValueError("retrained_preprocessor ä¸èƒ½ä¸º None")
        joblib.dump(retrained_preprocessor, preprocessor_file)
        saved_files['preprocessor'] = preprocessor_file
        print(f"âœ… é¢„å¤„ç†å™¨å·²ä¿å­˜: {preprocessor_file}")
    except Exception as e:
        error_msg = f"ä¿å­˜é¢„å¤„ç†å™¨å¤±è´¥: {e}"
        print(f"âŒ {error_msg}")
        errors.append(error_msg)
        preprocessor_file = None
    
    # å¦‚æœå…³é”®ç»„ä»¶ä¿å­˜å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
    if gmm_file is None or dl_file is None or preprocessor_file is None:
        error_summary = "\n".join(errors)
        raise RuntimeError(f"å…³é”®ç»„ä»¶ä¿å­˜å¤±è´¥ï¼Œæ— æ³•ç»§ç»­:\n{error_summary}")
    
    # 4. æå–å¹¶ä¿å­˜è®­ç»ƒå†å²
    history_dict = None
    if training_results is not None and 'history' in training_results:
        history = training_results['history']
        if history is not None:
            if hasattr(history, 'history'):
                history_dict = history.history
            elif isinstance(history, dict):
                history_dict = history
    
    # 5. æå–å¹¶ä¿å­˜ROCæ›²çº¿æ•°æ®
    fpr, tpr, test_auc, y_test_pred = None, None, None, None
    splits = {}
    if training_results is not None:
        splits = training_results.get('splits', {})
    
    if splits and splits.get('X_test') is not None and splits.get('y_test') is not None:
        try:
            if model_type != 'rf':
                y_test_pred = dl_model.predict(splits['X_test'], verbose=0).ravel()
            else:
                y_test_pred = dl_model.predict(splits['X_test']).ravel()
            
            fpr, tpr, _ = roc_curve(splits['y_test'], y_test_pred)
            test_auc = float(training_results.get('test_auc') or auc(fpr, tpr))
        except Exception as e:
            print(f"âš ï¸ è®¡ç®—ROCæ›²çº¿æ•°æ®å¤±è´¥: {e}")
    
    # 6. ä¿å­˜æµ‹è¯•æ•°æ®
    test_data_file = os.path.join(save_dir, f"{model_name}_test_data.npz")
    np.savez_compressed(test_data_file,
                       X_test=splits.get('X_test'),
                       y_test=splits.get('y_test'),
                       X_train=splits.get('X_train'),
                       y_train=splits.get('y_train'),
                       X_val=splits.get('X_val'),
                       y_val=splits.get('y_val'),
                       y_test_pred=y_test_pred,
                       fpr=fpr,
                       tpr=tpr,
                       test_auc=test_auc)
    
    # 7. ä¿å­˜é…ç½®ä¿¡æ¯
    config_info = {
        'features': features,
        'model_config': config,
        'training_strategy': {
            'negative_strategy': negative_strategy,
            'train_mode': train_mode,
            'model_type': model_type,
            'models_to_train': models_to_train if train_mode == 'multiple' else None
        },
        'dl_architecture': None,
        'training_metrics': training_results.get('metrics', {}),
        'timestamp': timestamp,
        'version': '3.0'
    }
    
    # ä¿å­˜è®­ç»ƒå†å²
    if history_dict is not None:
        try:
            history_serializable = {}
            for key, values in history_dict.items():
                if isinstance(values, (list, np.ndarray)):
                    history_serializable[key] = [
                        float(v) if isinstance(v, (np.floating, float, np.integer, int)) else v 
                        for v in values
                    ]
                else:
                    history_serializable[key] = values
            config_info['training_history'] = history_serializable
            print("âœ… è®­ç»ƒå†å²å·²ä¿å­˜åˆ°é…ç½®æ–‡ä»¶")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜è®­ç»ƒå†å²å¤±è´¥: {e}")
            config_info['training_history'] = None
    
    # ä¿å­˜å­¦ä¹ æ›²çº¿åˆ†æç»“æœ
    lc_analysis = None
    if training_results is not None:
        lc_analysis = training_results.get('learning_curve_results')
    if lc_analysis is not None:
        lc_serializable = {}
        
        # ä¿å­˜åŸºæœ¬æ•°æ®
        for key in ['train_sizes', 'train_scores_mean', 'train_scores_std', 
                   'val_scores_mean', 'val_scores_std', 'input_dim']:
            if key in lc_analysis:
                value = lc_analysis[key]
                if isinstance(value, np.ndarray):
                    lc_serializable[key] = value.tolist()
                elif isinstance(value, (list, tuple)):
                    lc_serializable[key] = [float(v) if isinstance(v, (np.floating, float)) else v for v in value]
                else:
                    lc_serializable[key] = float(value) if isinstance(value, (np.floating, float)) else value
        
        # ä¿å­˜åŸå§‹CVæ•°æ®
        for key in ['train_scores', 'val_scores']:
            if key in lc_analysis:
                value = lc_analysis[key]
                if isinstance(value, np.ndarray):
                    lc_serializable[key] = value.tolist()
        
        # ä¿å­˜è¿‡æ‹Ÿåˆåˆ†æç»“æœ
        if 'overfitting_analysis' in lc_analysis:
            of_analysis = lc_analysis['overfitting_analysis']
            of_serializable = {}
            for key, value in of_analysis.items():
                if isinstance(value, np.ndarray):
                    of_serializable[key] = value.tolist()
                elif isinstance(value, (list, tuple)):
                    of_serializable[key] = [float(v) if isinstance(v, (np.floating, float)) else v for v in value]
                elif isinstance(value, (np.floating, float, np.integer, int)):
                    of_serializable[key] = float(value)
                else:
                    of_serializable[key] = value
            lc_serializable['overfitting_analysis'] = of_serializable
        
        # ä¿å­˜å…¶ä»–é…ç½®ä¿¡æ¯
        for key in ['cv_config', 'model_config', 'data_shapes']:
            if key in lc_analysis:
                value = lc_analysis[key]
                if isinstance(value, dict):
                    serializable = {}
                    for k, v in value.items():
                        if isinstance(v, (np.ndarray, list, tuple)):
                            serializable[k] = v.tolist() if isinstance(v, np.ndarray) else list(v)
                        elif isinstance(v, tuple):
                            serializable[k] = list(v)
                        else:
                            serializable[k] = v
                    lc_serializable[key] = serializable
        
        # ä¿å­˜å…¶ä»–æŒ‡æ ‡
        for key in ['final_performance', 'overfitting_detected', 'high_variance']:
            if key in lc_analysis:
                value = lc_analysis[key]
                if isinstance(value, (np.floating, float, np.integer, int)):
                    lc_serializable[key] = float(value)
                else:
                    lc_serializable[key] = value
        
        config_info['learning_curve_analysis'] = lc_serializable
        print("âœ… å­¦ä¹ æ›²çº¿åˆ†æç»“æœå·²ä¿å­˜åˆ°é…ç½®æ–‡ä»¶")
    
    # ä¿å­˜PUè¯„ä¼°ç»“æœ
    if pu_evaluation is not None:
        pu_serializable = {}
        
        # ä¿å­˜æœ€ä½³ç»“æœ
        if 'best' in pu_evaluation:
            best = pu_evaluation['best']
            best_serializable = {}
            for key, value in best.items():
                if isinstance(value, (np.ndarray, list, tuple)):
                    best_serializable[key] = value.tolist() if isinstance(value, np.ndarray) else list(value)
                elif isinstance(value, (np.floating, float, np.integer, int)):
                    best_serializable[key] = float(value)
                elif isinstance(value, bool):
                    best_serializable[key] = value
                else:
                    best_serializable[key] = value
            pu_serializable['best'] = best_serializable
        
        # ä¿å­˜å®Œæ•´è¡¨æ ¼ï¼ˆæ‰€æœ‰é˜ˆå€¼çš„ç»“æœï¼‰
        if 'table' in pu_evaluation:
            table_serializable = []
            for row in pu_evaluation['table']:
                row_serializable = {}
                for key, value in row.items():
                    if isinstance(value, (np.ndarray, list, tuple)):
                        row_serializable[key] = value.tolist() if isinstance(value, np.ndarray) else list(value)
                    elif isinstance(value, (np.floating, float, np.integer, int)):
                        row_serializable[key] = float(value)
                    elif isinstance(value, bool):
                        row_serializable[key] = value
                    else:
                        row_serializable[key] = value
                table_serializable.append(row_serializable)
            pu_serializable['table'] = table_serializable
        
        # ä¿å­˜å…¶ä»–ä¿¡æ¯
        for key in ['reliable_count', 'recommendation', 'cost_ratio', 'config']:
            if key in pu_evaluation:
                pu_serializable[key] = pu_evaluation[key]
        
        config_info['pu_evaluation'] = pu_serializable
        print("âœ… PUè¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°é…ç½®æ–‡ä»¶")
    
    # ä¿å­˜æ¨¡å‹æ¶æ„ä¿¡æ¯
    if dl_model is not None:
        if hasattr(dl_model, 'input_shape') and model_type != 'rf':
            try:
                config_info['dl_architecture'] = {
                    'input_shape': list(dl_model.input_shape) if dl_model.input_shape else None,
                    'output_shape': list(dl_model.output_shape) if dl_model.output_shape else None,
                    'layers': [layer.get_config() for layer in dl_model.layers] if hasattr(dl_model, 'layers') else None
                }
            except Exception as e:
                print(f"âš ï¸ ä¿å­˜æ¨¡å‹æ¶æ„ä¿¡æ¯å¤±è´¥: {e}")
                config_info['dl_architecture'] = None
        elif model_type == 'rf':
            config_info['dl_architecture'] = {
                'model_type': 'RandomForest',
                'n_features': len(features),
                'feature_names': features
            }
    
    # ä¿å­˜é…ç½®æ–‡ä»¶
    config_file = os.path.join(save_dir, f"{model_name}_config.json")
    with open(config_file, 'w') as f:
        json.dump(config_info, f, indent=2, default=str)
    
    # åˆ›å»ºä¸»æ¨¡å‹æ–‡ä»¶
    version_tag = f"{model_type}_{negative_strategy}_{train_mode}"
    main_model = {
        'gmm_pipeline_path': gmm_file if gmm_file else None,
        'dl_model_path': dl_file if dl_file else None,
        'preprocessor_path': preprocessor_file if preprocessor_file else None,
        'test_data_path': test_data_file,
        'config_path': config_file,
        'features': features,
        'metadata': {
            'created_at': timestamp,
            'model_type': 'GMM+DeepLearning',
            'learning_model': model_desc,
            'negative_strategy': strategy_desc,
            'train_mode': train_mode,
            'model_details': {
                'single_model_type': model_type if train_mode == 'single' else None,
                'multi_models': models_to_train if train_mode == 'multiple' else None,
                'strategy_type': negative_strategy
            },
            'description': f'Landuse classification with {strategy_desc} negative sampling ({model_desc})',
            'version': '3.0',
            'version_tag': version_tag,
            'has_training_history': history_dict is not None,
            'has_learning_curve': lc_analysis is not None,
            'has_roc_data': fpr is not None and tpr is not None,
            'has_pu_evaluation': pu_evaluation is not None,
            'save_errors': errors if errors else None  # è®°å½•ä¿å­˜è¿‡ç¨‹ä¸­çš„é”™è¯¯
        }
    }
    
    main_file = os.path.join(save_dir, f"{model_name}.pkl")
    joblib.dump(main_model, main_file)
    
    print(f"\nâœ… å®Œæ•´æ¨¡å‹ä¿å­˜æˆåŠŸ (ç‰ˆæœ¬ 3.0):")
    print(f"  - ä¸»æ–‡ä»¶: {main_file}")
    print(f"  - GMMæ¨¡å‹: {gmm_file}")
    print(f"  - æ·±åº¦å­¦ä¹ æ¨¡å‹: {dl_file}")
    print(f"  - é¢„å¤„ç†å™¨: {preprocessor_file}")
    print(f"  - æµ‹è¯•æ•°æ®: {test_data_file}")
    print(f"  - é…ç½®æ–‡ä»¶: {config_file}")
    print(f"\nğŸ“‹ æ¨¡å‹ä¿¡æ¯:")
    print(f"  - å­¦ä¹ æ¨¡å‹: {model_desc}")
    print(f"  - é‡‡æ ·ç­–ç•¥: {strategy_desc}")
    print(f"  - è®­ç»ƒæ¨¡å¼: {train_mode}")
    print(f"  - ç‰ˆæœ¬æ ‡ç­¾: {version_tag}")
    print(f"\nğŸ“Š ä¿å­˜çš„æ•°æ®:")
    print(f"  - è®­ç»ƒå†å²: {'âœ…' if history_dict else 'âŒ'}")
    print(f"  - å­¦ä¹ æ›²çº¿: {'âœ…' if lc_analysis else 'âŒ'}")
    print(f"  - ROCæ•°æ®: {'âœ…' if fpr is not None else 'âŒ'}")
    print(f"  - PUè¯„ä¼°: {'âœ…' if pu_evaluation else 'âŒ'}")
    print(f"  - æ€§èƒ½æŒ‡æ ‡: âœ…")
    
    return main_file


def load_complete_model_pipeline(main_model_file):
    """
    åŠ è½½å®Œæ•´æ¨¡å‹ç®¡é“ï¼ˆå¢å¼ºç‰ˆä¿¡æ¯æ˜¾ç¤ºï¼‰
    """
    try:
        # åŠ è½½ä¸»æ¨¡å‹æ–‡ä»¶
        main_model = joblib.load(main_model_file)
        
        # åŠ è½½å„ä¸ªç»„ä»¶
        gmm_pipeline = joblib.load(main_model['gmm_pipeline_path'])
        
        if TENSORFLOW_AVAILABLE:
            dl_model = keras.models.load_model(main_model['dl_model_path'])
        else:
            # å¦‚æœæ˜¯RFæ¨¡å‹ï¼Œä½¿ç”¨joblibåŠ è½½
            dl_model = joblib.load(main_model['dl_model_path'])
        
        preprocessor = joblib.load(main_model['preprocessor_path'])
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        if 'test_data_path' in main_model:
            test_data = np.load(main_model['test_data_path'])
            test_data_dict = {
                'X_test': test_data.get('X_test'),
                'y_test': test_data.get('y_test'),
                'X_train': test_data.get('X_train'),
                'y_train': test_data.get('y_train'),
                'X_val': test_data.get('X_val'),
                'y_val': test_data.get('y_val')
            }
            print("âœ… æµ‹è¯•æ•°æ®åŠ è½½æˆåŠŸ")
        else:
            test_data_dict = None
            print("âš ï¸ è¯¥æ¨¡å‹æ²¡æœ‰ä¿å­˜æµ‹è¯•æ•°æ®")
        
        with open(main_model['config_path'], 'r') as f:
            config = json.load(f)
        
        # å¢å¼ºç‰ˆä¿¡æ¯æ˜¾ç¤º
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ:")
        print(f"  - åˆ›å»ºæ—¶é—´: {main_model['metadata']['created_at']}")
        print(f"  - æ¨¡å‹ç±»å‹: {main_model['metadata']['model_type']}")
        print(f"  - å­¦ä¹ æ¨¡å‹: {main_model['metadata'].get('learning_model', 'N/A')}")
        print(f"  - é‡‡æ ·ç­–ç•¥: {main_model['metadata'].get('negative_strategy', 'N/A')}")
        print(f"  - è®­ç»ƒæ¨¡å¼: {main_model['metadata'].get('train_mode', 'N/A')}")
        print(f"  - ç‰¹å¾æ•°é‡: {len(main_model['features'])}")
        print(f"  - ç‰ˆæœ¬: {main_model['metadata'].get('version', '1.0')}")
        print(f"  - ç‰ˆæœ¬æ ‡ç­¾: {main_model['metadata'].get('version_tag', 'N/A')}")
        
        return {
            'gmm_pipeline': gmm_pipeline,
            'dl_model': dl_model,
            'preprocessor': preprocessor,
            'features': main_model['features'],
            'config': config,
            'metadata': main_model['metadata'],
            'test_data': test_data_dict  
        }
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

