# -*- coding: utf-8 -*-
"""
è®­ç»ƒæ¨¡å—
åŒ…å«è®­ç»ƒå›è°ƒã€å•æ¨¡å‹è®­ç»ƒã€å¤šæ¨¡å‹è®­ç»ƒç­‰åŠŸèƒ½
"""

from __future__ import annotations

import time
import numpy as np
import pandas as pd
from sklearn.base import clone
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_curve, auc, mean_squared_error, mean_absolute_error
)

# æ·±åº¦å­¦ä¹ åº“
# å…ˆå®šä¹‰å ä½ç¬¦ï¼Œç¡®ä¿ Callback æ€»æ˜¯å­˜åœ¨ï¼Œé¿å… NameError
class _PlaceholderCallback:
    pass

_tf = None
Callback = _PlaceholderCallback
TENSORFLOW_AVAILABLE = False

def _ensure_tensorflow():
    """ç¡®ä¿ TensorFlow å·²å¯¼å…¥ï¼Œå¦‚æœä¹‹å‰å¤±è´¥åˆ™é‡è¯•"""
    global _tf, Callback, TENSORFLOW_AVAILABLE
    if TENSORFLOW_AVAILABLE and _tf is not None:
        return True
    
    try:
        import sys
        original_recursion_limit = sys.getrecursionlimit()
        sys.setrecursionlimit(max(original_recursion_limit, 3000))
        
        import tensorflow as tf
        keras = tf.keras
        Callback = keras.callbacks.Callback
        _tf = tf
        TENSORFLOW_AVAILABLE = True
        
        # æ¢å¤é€’å½’æ·±åº¦é™åˆ¶
        sys.setrecursionlimit(original_recursion_limit)
        
        if _tf is not None:  # é¿å…é‡å¤æ‰“å°
            print("âœ… TensorFlow imported successfully")
        return True
    except RecursionError as e:
        TENSORFLOW_AVAILABLE = False
        print(f"âš ï¸ TensorFlow import recursion error: {type(e).__name__}: {e}")
        print("âš ï¸ This may be a TensorFlow 2.15 compatibility issue")
        Callback = _PlaceholderCallback
        return False
    except Exception as e:
        if not TENSORFLOW_AVAILABLE:  # åªåœ¨é¦–æ¬¡å¤±è´¥æ—¶æ‰“å°
            print(f"âš ï¸ TensorFlow import failed: {type(e).__name__}: {e}")
            print("âš ï¸ Some features will be disabled")
        TENSORFLOW_AVAILABLE = False
        Callback = _PlaceholderCallback
        return False

# å»¶è¿Ÿå¯¼å…¥ï¼šä¸åœ¨æ¨¡å—çº§åˆ«ç«‹å³è°ƒç”¨ï¼Œé¿å…å¾ªç¯å¯¼å…¥å’Œé€’å½’é”™è¯¯
# _ensure_tensorflow()  # æ³¨é‡Šæ‰ï¼Œæ”¹ä¸ºåœ¨éœ€è¦æ—¶è°ƒç”¨

# å¯¼å…¥æ¨¡å‹æ„å»ºæ¨¡å—
from .model_building import (
    build_deep_learning_model,
    build_transformer_resnet_model,
    RandomForestWrapper
)

# å¯¼å…¥å­¦ä¹ æ›²çº¿æ¨¡å—
from .learning_curve import plot_learning_curve_nn

# å¯¼å…¥è¯„ä¼°æ¨¡å—
from .evaluation import plot_training_results


def train_and_evaluate_model(
    df_combined_training, features_no_coords, gmm_preprocessor, 
    test_size=0.2, val_size=0.2, epochs=50, 
    batch_size=32, random_state=42,
    hidden_layers=[128, 64, 32], dropout_rate=0.3, learning_rate=0.001,
    plot_learning_curve=True, learning_curve_epochs=30,
    model_type="transformer",  
    transformer_config={'d_model': 64, 'num_heads': 4, 'num_layers': 2},  
    rf_config={'n_estimators': 100, 'max_depth': 15},
    resnet_layers=[128, 128, 64]
):
    """
    è®­ç»ƒå’Œè¯„ä¼°å•ä¸ªæ¨¡å‹
    """
    try:
        # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
        np.random.seed(random_state)
        # ç¡®ä¿ TensorFlow å·²å¯¼å…¥ï¼ˆå¦‚æœä¹‹å‰å¤±è´¥åˆ™é‡è¯•ï¼‰
        if _ensure_tensorflow():
            _tf.random.set_seed(random_state)
            
            # å¦‚æœä½¿ç”¨GPUï¼Œè¿˜éœ€è¦è®¾ç½®è¿™äº›
            try:
                _tf.config.experimental.enable_op_determinism()
                print("âœ… TensorFlowç¡®å®šæ€§æ¨¡å¼å·²å¯ç”¨")
            except Exception:
                print("â„¹ï¸ TensorFlowç¡®å®šæ€§æ¨¡å¼è®¾ç½®è·³è¿‡")
        
        # 1. å‡†å¤‡åŸå§‹æ•°æ®
        print("å‡†å¤‡åŸå§‹æ•°æ®...")
        X = df_combined_training[features_no_coords]
        y = df_combined_training['label'].values.astype(int)
        
        print(f"åŸå§‹ç‰¹å¾: {X.shape}")
        print(f"æ ‡ç­¾åˆ†å¸ƒ: æ­£æ ·æœ¬={y.sum()}, è´Ÿæ ·æœ¬={len(y)-y.sum()}, æ­£æ ·æœ¬æ¯”ä¾‹={y.mean():.3f}")
        
        # 2. å…ˆåˆ’åˆ†åŸå§‹æ•°æ®ï¼ˆæœªé¢„å¤„ç†çš„ï¼‰
        print("å…ˆåˆ’åˆ†åŸå§‹æ•°æ®...")
        
        # ç¬¬ä¸€æ¬¡åˆ’åˆ†ï¼šåˆ†ç¦»æµ‹è¯•é›†
        X_temp, X_test_raw, y_temp, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state, stratify=y
        )
        
        # ç¬¬äºŒæ¬¡åˆ’åˆ†ï¼šä»å‰©ä½™æ•°æ®ä¸­åˆ†ç¦»éªŒè¯é›†
        val_size_adjusted = val_size / (1 - test_size)
        X_train_raw, X_val_raw, y_train, y_val = train_test_split(
            X_temp, y_temp, test_size=val_size_adjusted, random_state=random_state, stratify=y_temp
        )
        
        print(f"åŸå§‹æ•°æ®åˆ’åˆ†å®Œæˆ:")
        print(f"  è®­ç»ƒé›†: {X_train_raw.shape} (æ­£æ ·æœ¬æ¯”ä¾‹: {y_train.mean():.3f})")
        print(f"  éªŒè¯é›†: {X_val_raw.shape} (æ­£æ ·æœ¬æ¯”ä¾‹: {y_val.mean():.3f})")
        print(f"  æµ‹è¯•é›†: {X_test_raw.shape} (æ­£æ ·æœ¬æ¯”ä¾‹: {y_test.mean():.3f})")
        
        # 3. å…‹éš†é¢„å¤„ç†å™¨å¹¶åœ¨è®­ç»ƒé›†ä¸Šé‡æ–°æ‹Ÿåˆ
        print("åœ¨è®­ç»ƒé›†ä¸Šé‡æ–°æ‹Ÿåˆé¢„å¤„ç†å™¨...")
        
        # å…‹éš†GMMé¢„å¤„ç†å™¨çš„ç»“æ„
        train_preprocessor = clone(gmm_preprocessor)
        
        # åœ¨è®­ç»ƒé›†ï¼ˆæ­£+è´Ÿæ ·æœ¬ï¼‰ä¸Šé‡æ–°æ‹Ÿåˆ
        train_preprocessor.fit(X_train_raw)
        
        print("âœ… é¢„å¤„ç†å™¨å·²åœ¨è®­ç»ƒé›†ä¸Šé‡æ–°æ‹Ÿåˆï¼ˆé¿å…æ­£æ ·æœ¬åå·®ï¼‰")
        
        # 4. å­¦ä¹ æ›²çº¿åˆ†æ
        lc_analysis = None  
        if plot_learning_curve:
            try:
                print("\næ‰§è¡Œå­¦ä¹ æ›²çº¿åˆ†æï¼ˆä»…è®­ç»ƒé›†ï¼Œæ— æ³„éœ²ï¼‰...")
                
                if not _ensure_tensorflow():
                    print("âš ï¸ TensorFlow ä¸å¯ç”¨ï¼Œè·³è¿‡å­¦ä¹ æ›²çº¿åˆ†æ")
                    lc_analysis = None
                else:
                    try:
                        from scikeras.wrappers import KerasClassifier
                        SCIKERAS_AVAILABLE = True
                    except ModuleNotFoundError as e:
                        if 'keras.api' in str(e):
                            print(f"âš ï¸ scikeras version incompatible with TensorFlow 2.11: {e}")
                            print("ğŸ’¡ Try upgrading scikeras: pip install --upgrade scikeras>=0.12.0")
                            raise ImportError("scikeras not available due to version incompatibility")
                        SCIKERAS_AVAILABLE = False
                        raise ImportError(f"scikeras not available: {e}")
                    except ImportError as e:
                        SCIKERAS_AVAILABLE = False
                        raise ImportError(f"scikeras not available: {e}")
                    
                    if not SCIKERAS_AVAILABLE:
                        raise ImportError("scikeras not available")
                
                # æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½® build_model_fn
                build_model_fn = None
                if model_type == "transformer":
                    # ä¸ºTransformeråˆ›å»ºåŒ…è£…å‡½æ•°
                    def build_transformer_for_lc(
                        input_dim, 
                        hidden_layers=None,  # ä¿ç•™ä»¥å…¼å®¹æ¥å£ï¼Œä½†å®é™…ä¸ä½¿ç”¨
                        dropout_rate=0.3, 
                        learning_rate=0.001,
                        d_model=96,
                        num_heads=4,
                        num_transformer_layers=2,
                        resnet_layers=[128, 128, 64]
                    ):
                        """ä¸ºå­¦ä¹ æ›²çº¿æ„å»ºTransformer+ResNetæ¨¡å‹çš„åŒ…è£…å‡½æ•°"""
                        return build_transformer_resnet_model(
                            input_dim, 
                            d_model=d_model,
                            num_heads=num_heads,
                            num_transformer_layers=num_transformer_layers,
                            resnet_layers=resnet_layers,
                            dropout_rate=dropout_rate,
                            learning_rate=learning_rate
                        )
                    build_model_fn = build_transformer_for_lc
                    print("âœ… ä½¿ç”¨Transformeræ¨¡å‹è¿›è¡Œå­¦ä¹ æ›²çº¿åˆ†æ")
                elif model_type == "rf":
                    # RFæ¨¡å‹ä¸æ”¯æŒå­¦ä¹ æ›²çº¿åˆ†æï¼ˆæˆ–éœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
                    print("â„¹ï¸ Random Forestæ¨¡å‹è·³è¿‡å­¦ä¹ æ›²çº¿åˆ†æï¼ˆscikerasä¸ç›´æ¥æ”¯æŒï¼‰")
                    lc_analysis = None
                else:
                    # MLPæˆ–å…¶ä»–æ·±åº¦å­¦ä¹ æ¨¡å‹
                    build_model_fn = build_deep_learning_model
                    print("âœ… ä½¿ç”¨MLPæ¨¡å‹è¿›è¡Œå­¦ä¹ æ›²çº¿åˆ†æ")
                
                # å¦‚æœæœ‰ build_model_fnï¼Œè°ƒç”¨å­¦ä¹ æ›²çº¿åˆ†æï¼ˆé€‚ç”¨äº transformer å’Œ mlpï¼‰
                if build_model_fn is not None:
                    lc_analysis = plot_learning_curve_nn(
                        build_model_fn=build_model_fn,
                        X_raw=X_train_raw,  
                        y=y_train,         
                        features_no_coords=features_no_coords,
                        preprocessor_instance=gmm_preprocessor,  
                        epochs=learning_curve_epochs,
                        cv_splits=5,
                        random_state=random_state,
                        hidden_layers=hidden_layers,
                        dropout_rate=dropout_rate,
                        learning_rate=learning_rate,
                        transformer_config=transformer_config if model_type == "transformer" else None,
                        resnet_layers=resnet_layers if model_type == "transformer" else None
                    )
                    
                    if lc_analysis:
                        print("âœ… å­¦ä¹ æ›²çº¿åˆ†æå®Œæˆ")
                    else:
                        print("âš ï¸ å­¦ä¹ æ›²çº¿åˆ†æå¤±è´¥")
                        
            except Exception as e:
                print(f"âš ï¸ å­¦ä¹ æ›²çº¿åˆ†æå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                lc_analysis = None
        
        # 5. åˆ†åˆ«transformä¸‰ä¸ªå­é›†
        print("åˆ†åˆ«é¢„å¤„ç†ä¸‰ä¸ªæ•°æ®é›†...")
        
        X_train = train_preprocessor.transform(X_train_raw)
        X_val = train_preprocessor.transform(X_val_raw)
        X_test = train_preprocessor.transform(X_test_raw)
        
        print(f"é¢„å¤„ç†åæ•°æ®å½¢çŠ¶:")
        print(f"  è®­ç»ƒé›†: {X_train.shape}")
        print(f"  éªŒè¯é›†: {X_val.shape}")
        print(f"  æµ‹è¯•é›†: {X_test.shape}")
        
        # 6. æ„å»ºæ¨¡å‹
        print(f"æ„å»º{model_type.upper()}æ¨¡å‹...")
        input_dim = X_train.shape[1]
        if _ensure_tensorflow():
            _tf.random.set_seed(random_state)
        
        if model_type == "transformer":
            model = build_transformer_resnet_model(
                input_dim=input_dim,
                d_model=transformer_config['d_model'],
                num_heads=transformer_config['num_heads'],
                num_transformer_layers=transformer_config['num_layers'],
                resnet_layers=resnet_layers,
                dropout_rate=dropout_rate,
                learning_rate=learning_rate
            )
        elif model_type == "rf":
            model = RandomForestWrapper(
                n_estimators=rf_config['n_estimators'],
                max_depth=rf_config['max_depth'],
                random_state=random_state
            )
        else:  # "mlp"
            model = build_deep_learning_model(input_dim, hidden_layers, dropout_rate, learning_rate)
        
        # 7. è®­ç»ƒæ¨¡å‹
        print("\n" + "="*60)
        print("å¼€å§‹æ¨¡å‹è®­ç»ƒ")
        print("="*60)
        print(f"æ¨¡å‹ç±»å‹: {model_type}")
        print(f"è®­ç»ƒæ ·æœ¬: {len(X_train)}")
        print(f"éªŒè¯æ ·æœ¬: {len(X_val)}")
        print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"è®­ç»ƒè½®æ•°: {epochs}")
        
        if _ensure_tensorflow():
            _tf.random.set_seed(random_state)
        
        if model_type != "rf":
            if _ensure_tensorflow():
                physical_devices = _tf.config.list_physical_devices('GPU')
                
                if physical_devices:
                    device_name = "/GPU:0"
                    print(f"è®­ç»ƒè®¾å¤‡: GPU ğŸš€")
                    print(f"  è®¾å¤‡: {physical_devices[0].name}")
                else:
                    device_name = "/CPU:0"
                    print(f"è®­ç»ƒè®¾å¤‡: CPU")
                
                # ä½¿ç”¨ Keras å†…ç½®çš„è¿›åº¦æ˜¾ç¤ºï¼Œé¿å…è‡ªå®šä¹‰å›è°ƒçš„å…¼å®¹æ€§é—®é¢˜
                # verbose=1 æ˜¾ç¤ºè¿›åº¦æ¡ï¼Œverbose=2 æ˜¾ç¤ºæ¯ä¸ª epoch ä¸€è¡Œ
                with _tf.device(device_name):
                    history = model.fit(
                        X_train, y_train,
                        validation_data=(X_val, y_val),
                        epochs=epochs, 
                        batch_size=batch_size, 
                        verbose=2,  # ä½¿ç”¨å†…ç½®è¿›åº¦æ˜¾ç¤º
                        callbacks=[]  # ä¸ä½¿ç”¨è‡ªå®šä¹‰å›è°ƒ
                    )
            else:
                raise ImportError("TensorFlow not available for training")
        else:
            print("è®­ç»ƒè®¾å¤‡: CPU (Random Forest)")
            model.fit(X_train, y_train, verbose=0)
            
            class MockHistory:
                """ä¸ºRFæ¨¡å‹åˆ›å»ºå ä½çš„historyå¯¹è±¡"""
                def __init__(self):
                    self.history = {
                        'loss': [],
                        'val_loss': [],
                        'accuracy': [],
                        'val_accuracy': []
                    }
            
            history = MockHistory()
        
        # 8. æ¨¡å‹è¯„ä¼°
        print("æ¨¡å‹è¯„ä¼°...")
        
        if model_type == "rf":
            # RFè¯„ä¼°ç»Ÿä¸€æ¥å£
            train_metrics = model.evaluate(X_train, y_train)
            val_metrics = model.evaluate(X_val, y_val)
            test_metrics = model.evaluate(X_test, y_test)
            test_auc = test_metrics['auc']
            y_test_pred = model.predict(X_test, verbose=0).ravel()
            fpr, tpr, _ = roc_curve(y_test, y_test_pred)
        else:
            y_train_pred = model.predict(X_train, verbose=0).ravel()
            y_train_bin = (y_train_pred > 0.5).astype(int)
            train_metrics = {
                'accuracy': accuracy_score(y_train, y_train_bin),
                'precision': precision_score(y_train, y_train_bin),
                'recall': recall_score(y_train, y_train_bin),
                'f1': f1_score(y_train, y_train_bin)
            }
            
            y_val_pred = model.predict(X_val, verbose=0).ravel()
            y_val_bin = (y_val_pred > 0.5).astype(int)
            val_metrics = {
                'accuracy': accuracy_score(y_val, y_val_bin),
                'precision': precision_score(y_val, y_val_bin),
                'recall': recall_score(y_val, y_val_bin),
                'f1': f1_score(y_val, y_val_bin)
            }
            
            y_test_pred = model.predict(X_test, verbose=0).ravel()
            y_test_bin = (y_test_pred > 0.5).astype(int)
            fpr, tpr, _ = roc_curve(y_test, y_test_pred)
            test_auc = auc(fpr, tpr)
            test_metrics = {
                'accuracy': accuracy_score(y_test, y_test_bin),
                'precision': precision_score(y_test, y_test_bin),
                'recall': recall_score(y_test, y_test_bin),
                'f1': f1_score(y_test, y_test_bin),
                'auc': test_auc
            }
        
        print(f"æµ‹è¯•é›†æ€§èƒ½: Acc={test_metrics['accuracy']:.4f} | "
              f"P={test_metrics['precision']:.4f} | R={test_metrics['recall']:.4f} | "
              f"F1={test_metrics['f1']:.4f} | AUC={test_metrics['auc']:.4f}")
        
        if model_type != "rf":
            plot_training_results(history, fpr, tpr, test_auc, y_test, y_test_pred)
        
        # æ¦‚ç‡é¢„æµ‹è¯„ä¼°
        if model_type == "rf" and 'y_test_pred' not in locals():
            y_test_pred = model.predict(X_test, verbose=0).ravel()
        
        mse = mean_squared_error(y_test, y_test_pred)
        mae = mean_absolute_error(y_test, y_test_pred)
        rmse = np.sqrt(mse)
        brier_score = np.mean((y_test - y_test_pred) ** 2)
        prob_metrics = {'mse': mse, 'mae': mae, 'rmse': rmse, 'brier_score': brier_score}
        
        results = {
            'model': model,
            'model_type': model_type,  
            'history': history,
            'splits': {
                'X_train': X_train, 'y_train': y_train,
                'X_val': X_val, 'y_val': y_val,
                'X_test': X_test, 'y_test': y_test
            },
            'preprocessor': train_preprocessor,
            'original_preprocessor': gmm_preprocessor,
            'metrics': {
                'train': train_metrics,
                'val': val_metrics,
                'test': test_metrics
            },
            'test_auc': test_auc,
            'probability_metrics': prob_metrics,
            'learning_curve_results': lc_analysis
        }
        
        print(f"âœ… {model_type.upper()} è®­ç»ƒå®Œæˆï¼")
        return results
        
    except Exception as e:
        print(f"âŒ Error in train_and_evaluate_model: {e}")
        import traceback
        traceback.print_exc()
        return None


def train_multiple_models(
    df_combined_training, features_no_coords, gmm_preprocessor,
    models_to_train=['transformer', 'mlp', 'rf'],  
    test_size=0.2, val_size=0.2, epochs=50, batch_size=32, random_state=42,
    hidden_layers=[128, 64, 32], dropout_rate=0.3, learning_rate=0.001,
    plot_learning_curve=True, learning_curve_epochs=30,
    transformer_config={'d_model': 64, 'num_heads': 4, 'num_layers': 2},
    rf_config={'n_estimators': 100, 'max_depth': 15},
    resnet_layers=[128, 128, 64]
):
    """
    ä¸€æ¬¡æ€§è®­ç»ƒå¤šä¸ªæ¨¡å‹å¹¶è¿”å›å¯¹æ¯”ç»“æœ
    
    Parameters:
    -----------
    models_to_train : list of str, è¦è®­ç»ƒçš„æ¨¡å‹ ['transformer', 'mlp', 'rf']
    
    Returns:
    --------
    dict : {
        'results': {model_name: training_results},
        'comparison': pd.DataFrame,
        'best_model': str,
        'splits': {'X_train', 'y_train', ...},
        'preprocessor': ...
    }
    """
    print("=" * 80)
    print("å¤šæ¨¡å‹è®­ç»ƒä¸å¯¹æ¯”")
    print("=" * 80)
    print(f"å°†è¦è®­ç»ƒ: {models_to_train}")
    
    all_results = {}
    
    # è®­ç»ƒæ¯ä¸ªæ¨¡å‹
    for model_name in models_to_train:
        print(f"\n{'='*60}")
        print(f"è®­ç»ƒ {model_name.upper()} æ¨¡å‹")
        print(f"{'='*60}")
        
        try:
            result = train_and_evaluate_model(
                df_combined_training, features_no_coords, gmm_preprocessor,
                test_size=test_size, val_size=val_size, epochs=epochs,
                batch_size=batch_size, random_state=random_state,
                hidden_layers=hidden_layers, dropout_rate=dropout_rate,
                learning_rate=learning_rate,
                plot_learning_curve=plot_learning_curve,
                learning_curve_epochs=learning_curve_epochs,
                model_type=model_name,
                transformer_config=transformer_config,
                rf_config=rf_config,
                resnet_layers=resnet_layers
            )
            
            if result is not None:
                all_results[model_name] = result
                print(f"âœ… {model_name.upper()} è®­ç»ƒæˆåŠŸ")
            else:
                print(f"âŒ {model_name.upper()} è®­ç»ƒå¤±è´¥")
                
        except Exception as e:
            print(f"âŒ {model_name.upper()} è®­ç»ƒå‡ºé”™: {e}")
            all_results[model_name] = None
    
    if not all_results:
        print("âŒ æ‰€æœ‰æ¨¡å‹è®­ç»ƒéƒ½å¤±è´¥")
        return None
    
    # åˆ›å»ºå¯¹æ¯”è¡¨
    comparison_data = []
    for name, result in all_results.items():
        if result is not None:
            metrics = result['metrics']['test']
            comparison_data.append({
                'Model': name.upper(),
                'Accuracy': f"{metrics['accuracy']:.4f}",
                'Precision': f"{metrics['precision']:.4f}",
                'Recall': f"{metrics['recall']:.4f}",
                'F1': f"{metrics['f1']:.4f}",
                'AUC': f"{metrics['auc']:.4f}"
            })
    
    comparison_df = pd.DataFrame(comparison_data)
    
    print("\n" + "=" * 80)
    print("æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    print("=" * 80)
    print(comparison_df.to_string(index=False))
    
    # é€‰æ‹©æœ€ä½³æ¨¡å‹ï¼ˆåŸºäºF1åˆ†æ•°ï¼‰
    best_model = None
    best_f1 = -1
    for name, result in all_results.items():
        if result is not None:
            f1 = result['metrics']['test']['f1']
            if f1 > best_f1:
                best_f1 = f1
                best_model = name
    
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model.upper()} (F1={best_f1:.4f})")
    
    return {
        'results': all_results,
        'comparison': comparison_df,
        'best_model': best_model,
        'splits': all_results[best_model]['splits'],
        'preprocessor': all_results[best_model]['preprocessor']
    }

